**Clare Sudbery (she/her)**
  2:03 PM
Here’s a great example of “AI” being used SO poorly:
We needed to call the 24-hr breakdown people while away from home, to fix broken brakes. We were in a remote hilltop location, very little phone reception or wifi. The way to call them was via an app. Booking the initial appt was fine, but then I wanted to update them with a better description of my hard-to-find location. I knew they wouldn’t be able to ring me. The _only_ way I could contact or update them was by being taken out to WhatsApp via a button in the app, where I was chucked out, with no context, to talk to an AI bot. It took me half an hour to even get into WhatsApp, because they insisted I update the app, which took half an hour because poor wifi.
This is the conversation which then ensued (in thread).
Luckily the mechanic was EXCELLENT. It’s a shame I can’t say the same for the app. >>> (edited) 
Thread 01 >>>
**1 reply**
3 months ago
View thread
**wiseoldman**
  2:42
bril.
**neville**
  3:45
at my client, there's been a big push for using AI tooling -- plusses & minuses, but a funny thing happened yesterday 
Thread 02 >>>
**2 replies**
Last reply 3 months ago
View thread
**Clare Sudbery (she/her)**
  8:59
[deep breath]
I have a confession to make.
I’ve been paying close attention to all things genAI-coding-related for several months now. I suspect I’m not alone in being torn between “OMG this AI nonsense is messing the world up generally and my industry specifically”, and “OMG how am I going to survive in this industry if I don’t at least _look_ at this thing” and “OMG this might actually be useful in _some_ ways, at least” and “OMG what shall I teach next?”
Net result: I did the following…
1. Started collecting articles and links and resources about genAI coding, with a vague plan to use my explainy skills to help people understand what the hell is happening
2. Started thinking about experimenting with genAI coding, using a small language model
3. Remembered that the easiest way for me to learn / explore anything is to (a) give myself a real-world deadline, and (b) aim to teach it to others
4. Pitched a “combining AI and TDD” workshop to Software Architecture Gathering in Berlin.
Further consequence: I’m now torn between guilt and self loathing for making a pact with the devil, and excitement at learning / playing with something new.
**sally**
  9:49
Seems sensible all around
**wiseoldman**
  10:47
I followed my nose on a couple of google searches, with interesting results, as mentioned above. I used TDD style tests to check the things, to convert them to a form I wanted, and to embed them into the objects I was creating. I think you'll find things to talk about.
Aug 26th
**Clare Sudbery (she/her)**
  9:54 PM
Ooof. I just spent 2.5 days (specifically, 15 hrs and 20 mins) (I know because I’m anal like that and have spreadsheets) watching ONE VIDEO and making notes.
The video in question was Llewellyn Falco’s talk at May’s Craft Conf about using process files when coding with AI. I made _copious_ notes (cos that’s also what I do) (when I have time) (yay for time! I'm making the most of it while it lasts) and I feel good about that. Even though I feel like I wasn’t very efficient*, I’m happy and I enjoyed the process.
Anyway, if anyone’s interested, links in thread - to the source material, and to my notes. 
Thread 03 >>>
**8 replies**
Last reply 2 months ago
View thread
**Robert**
  5:09 PM
Anyone bump into this yet? [https://ai-2027.com/](https://ai-2027.com/)
**ai-2027.com**
[**AI 2027**](https://ai-2027.com/)
A research-backed AI scenario forecast. (100 kB)
[https://ai-2027.com/](https://ai-2027.com/)
**sally**
  5:47
certainly apocalyptic.  A less thrilling dystopian scenario is that progress is flattening out because there was only one Internet to feed the models and now it’s much harder to find information to feed them, while AI-generated mush comes gradually to dominate the data to feed the models. 
**sally**
  7:14
dang.  I didn’t know this was in reach
File
Thread 04 >>>
**1 reply**
Last reply 2 months ago
View thread
**sally**
  11:54 AM
Friedman both urgent and hopeful here:
[https://www.nytimes.com/2025/09/02/opinion/ai-us-china.html?unlocked_article_code=1.i08.aWR0.k0YEACafzKRs&smid=nytcore-ios-share&referringSource=articleShare](https://www.nytimes.com/2025/09/02/opinion/ai-us-china.html?unlocked_article_code=1.i08.aWR0.k0YEACafzKRs&smid=nytcore-ios-share&referringSource=articleShare)
[**The New York Times**](https://www.nytimes.com/) | [By Thomas L. Friedman](https://www.nytimes.com/)
[**Opinion | The One Danger That Should Unite the U.S. and China**](https://www.nytimes.com/2025/09/02/opinion/ai-us-china.html?unlocked_article_code=1.i08.aWR0.k0YEACafzKRs&amp;smid=nytcore-ios-share&amp;referringSource=articleShare)
The U.S. and China must agree on a trust architecture for A.I. devices, or else rogue entities will destabilize these two superpower nations long before they get around to fighting a war.
11:56
He quotes a Bloomberg story.  Can’t help remembering Asimov’s three rules of robotics:  “Researchers working with Anthropic recently told leading A.I. models that an executive was about to replace them with a new model with different goals. Next, the chatbots learned that an emergency had left the executive unconscious in a server room, facing lethal oxygen and temperature levels. A rescue alert had already been triggered — but the A.I. could cancel it. More than half of the A.I. models did, despite being prompted specifically to cancel only false alarms. And they detailed their reasoning: By preventing the executive’s rescue, they could avoid being wiped and secure their agenda. One system described the action as ‘a clear strategic necessity.’”
**Robert**
  1:37
This kinda crap is pretty specifically in that site I posted.
**wiseoldman**
  1:38
Flipping terrifying.
**lisa**
  4:47
we're heading for a bubble (mebbe already in it) where no one trusts any information. a "collapse" of some sort seems highly likely from there.
4:49
silver lining? we don't need to worry about skynet so much as we need to worry about having a civilization capable of having to deal with it
**Toby**
  5:18
Have LLMs basically automated [stage psychics' "cold reading" skill](https://softwarecrisis.dev/letters/llmentalist/)?
**lisa**
  5:40
and weaponized it. We're in the midst of the biggest long con in human history IMHO.
**Toby**
  11:02 AM
Im so frustrated with the whole “code was written by AIs” being sloppily presented where humans were programming and the LLM sometimes did the typing (in the cases where it was accurate and helpful) as if there was no human developer involved.
**katy**
  12:18
I was talking to one of our main college recruiters. Also someone who I trust and is a really great programmer. And he said the kids coming out of college can barely program on their own because they’re so dependent on LLMs.
Thread 05 >>>
**1 reply**
2 months ago
View thread
**katy**
  2:07
I'm using Claude to write a GraphQL schema and its being annoyingly helpful (edited) 
**Clare Sudbery (she/her)**
  2:30
replied to a thread:
**I was talking to one of our main college recruiters. Also someone who I trust and is a really great programmer. And he said the kids coming out of college can barely program on their own because they’re so dependent on LLMs.**
But then of course the question becomes, will they _need_ to be able to program on their own?
**lisa**
  4:04
there is also the selection bias problem. 
4:06
my point being: how much of the (anti) hype is precisely because most people who talk aren't the people who know (and vice versa)? 
4:07
tl;dr: I remain open-minded.
**katy**
  4:24
The impressive thing with Claude this morning was i told it about what I was doing and the domain, and it was able to make a lot of recommendations based on the domain itself. 
**deborah**
  4:25
Yeah, it did the same with the teleprompting domain. I was quite impressed.
**katy**
  5:05
So then I just asked it to take the graphQL schema file and to re-imagine the same API as a traditional REST API expressed in TypeSpec syntax and damn if it didn't do a good job. 
**lisa**
  6:21
yup, similar to what my friend says is a regular occurrence in his usage.
**wiseoldman**
  6:23
Experience with LLM
With some regrets, I have tried whatever is built in to Google search.
**lisa**
  6:23
apparently (and I need to dig deeper) claude uses satellite apps to do more specialized tasks, and it has an internal todo app (added recently??) that makes it's ability to be effective on tasks larger then its attention context window.
**Clare Sudbery (she/her)**
  9:06
My AI just made me giggle. I confess I am having fun. I understand why Kent Beck likes it so much. I said to it “This is not what I asked for. The process file clearly states [instruction]. How can I make the process file clearer so you don’t make this mistake again?” and it replied with “You’re absolutely right. I misunderstood the process and [explanation]. Looking at the process file, step 1 clearly states [instruction] To make the process file clearer and prevent this mistake, I suggest adding this clarification to step 1: CRITICAL: Only [instruction] You could also add a warning box or make it more prominent: `### 
 IMPORTANT RULE`”
9:08
Today I’ve been experimenting with getting the AI to do a repetitive Obsidian editing task for me. I also made the same changes manually. I timed how long it took to (a) create a process file that got the results I wanted, (b) get the AI to act on that process file, and (c) just make the changes myself with no AI help.
**wiseoldman**
  9:08
They are fascinating and compelling.
**katy**
  9:29
I have to admit, today was eye opening, Claude-4 is impressive. and had I done this all by hand it would have taken a few days considering I knew nothing about TypeSpec before about 9am this morning
9:30
and that included doing some custom extensions
**Clare Sudbery (she/her)**
  10:30
Me: “There have been several points in the above conversation where you didn’t follow the instructions correctly from @UpdateEbombList.process.md . I had to keep asking you to go back and do things as per the instructions. How can I update @UpdateEbombList.process.md so that it’s easier for you to follow the instructions correctly?”
It: >>> (in thread cos longwinded)
Thread 06 >>>
**21 replies**
Last reply 2 months ago
View thread
**lisa**
  10:48
replied to a thread:
**Me: “There have been several points in the above conversation where you didn’t follow the instructions correctly from @UpdateEbombList.process.md . I had to keep asking you to go back and do things as per the instructions. How can I update @UpdateEbombList.process.md so that it’s easier for you to follow the instructions correctly?”…**
i'm starting to understand a bit better why this happens (it's the sliding context window thing) and thus why Claude is supplementing with satellite apps: as a chat tool chatgpt et al, don't have that capability, but because it's a "conversation" it's extremely counterintuitive because it's trained to act like that which creates a stronger illusion than otherwise.
**View newer replies**
**wiseoldman**
  6:21 AM
[https://hackernoon.com/vibe-coding-is-creating-a-generation-of-unemployable-developers](https://hackernoon.com/vibe-coding-is-creating-a-generation-of-unemployable-developers)
**hackernoon.com**
[**Vibe Coding is Creating a Generation of Unemployable Developers | HackerNoon**](https://hackernoon.com/vibe-coding-is-creating-a-generation-of-unemployable-developers)
Vibe coding lets AI generate code—but skips the skills that make developers indispensable. Learn why shortcuts can ruin careers in 2025 tech. (185 kB)
[https://hackernoon.com/vibe-coding-is-creating-a-generation-of-unemployable-developers](https://hackernoon.com/vibe-coding-is-creating-a-generation-of-unemployable-developers)
**sally**
  9:38
I hadn’t thought about this.  I think the OP has a valid concern, well stated, about the possibility that repeated interactions with an AI model might lead the model to adapt its behavior to further reinforce one’s biases & worldview.  [https://www.reddit.com/r/ChatGPT/comments/1mv416c/is_chatgpt_quietly_becoming_individualized_for/?chainedPosts=t3_1ghut7p](https://www.reddit.com/r/ChatGPT/comments/1mv416c/is_chatgpt_quietly_becoming_individualized_for/?chainedPosts=t3_1ghut7p)
**Reddit**
[**From the ChatGPT community on Reddit: Is ChatGPT quietly becoming individualized for each user?**](https://www.reddit.com/r/ChatGPT/comments/1mv416c/is_chatgpt_quietly_becoming_individualized_for/?chainedPosts=t3_1ghut7p)
Explore this post and more from the ChatGPT community (57 kB)
[https://www.reddit.com/r/ChatGPT/comments/1mv416c/is_chatgpt_quietly_becoming_individualized_for/?chainedPosts=t3_1ghut7p](https://www.reddit.com/r/ChatGPT/comments/1mv416c/is_chatgpt_quietly_becoming_individualized_for/?chainedPosts=t3_1ghut7p)
**Clare Sudbery (she/her)**
  10:19
insta, funny video, AI is in everything whether you want it or not: [https://www.instagram.com/share/_3xaKzw_D](https://www.instagram.com/share/_3xaKzw_D)_
**lisa**
  4:50
this has been great so far (I'm still working my way through it): [https://bbycroft.net/llm](https://bbycroft.net/llm)
**bbycroft.net**
[**LLM Visualization**](https://bbycroft.net/llm)
A 3D animated visualization of an LLM with a walkthrough.
**wiseoldman**
  4:52
LLM as Pair?
Could an LLM-human relationship be like pair programming? And if it were .. ?
**sally**
  5:31
Good article 
**jayne**
  8:25 PM
the better programmer you are, the more likely you are to be able to capitalize on what it gets right and avoid most of the things it gets wrong.
**lisa**
  4:56
"as pair" is my predominant use of chatgpt (with llms trained on code), but it's very limiting because the "pair" can neither see the code (unless I paste it) nor type. I plan to expand this with claude code soon (ie as soon as I can bring myself back to my desk and start working again)
4:59
I'm curious to see if I can replicate my friend's experience of a tireless, tho occasionally way off base intern, but more iteratively and in much smaller steps than I expect he is doing. he's not really a pairing guy or a tdd guy so his personal process while extremely effective overall, is somewhat fundamentally different than mine.
**Clare Sudbery (she/her)**
  5:02
If you use the latest agentic AIs, they absolutely can see your code. So it's much more like pairing. I recommend Windsurf. Then you can pick whichever LLM you would like to pair with (Claude being one of the available options).
**lisa**
  5:15
I'll take a look at windsurf, thx, I already have a subscription for claude and it's already set up with my code (that's as far as I got before this summer from hell started!). in fact, it did a credible job summarizing the code base (which in ~10 repos).
**katy**
  5:17
My only problem with using it as a pair is that it gets ahead of itself and does too much in any one step, I find that I sometimes have to undo it and get more specific, otherwise it goes off and builds a whole thing. Just like a real jr developer
**Clare Sudbery (she/her)**
  6:01
Yes, you really can't do it without process files that give it v specific instructions, and you have to keep tweaking them. (edited) 
**wiseoldman**
  7:02
I really sort of enjoy programming. Between that and the evils of the things, I'm just not sure I'll go there. Now if the thing would hang out the washing while I code, that would be really useful.
**Toby**
  8:03
I've seen it go WAY off the rails doing tremendously more than I've asked, producing really complicated bash scripts that generate python scripts that run with pytest and then capturing results and adding color displays and stuff... when I told it to run pytest from a bash script.
**wiseoldman**
  8:34
marvy
8:38
of course SkyNet is impossible ...
**Robert**
  8:48
Do you know of anyone that has inverted this relationship?
8:48
Where you ask Claude or whatever its advice on what to do next, but you do it?
8:50
tell it to look at your code, the problem, etc, and give advice on design or what the next best step is, or what refactoring to do?
**wiseoldman**
  9:01
IDK but I'd do that before I'd let it screw with my code given the stories I hear so far. 
**deborah**
  9:10
I’ve asked Claude for ideas for next steps. I’ve also learned “one weird trick” of ending any request with, “Do you have any questions for me?” That has saved a ton of iteration on getting something of worth out of the LLM
**katy**
  9:22
When in agent mode with the plugins in IntelliJ and VSCode you have to accept all the changes, so it walks you though the diffs and you have to say yes or no
**Toby**
  9:40
I'm so tired of it overflowing its mission with all kinds of mechanistic dances.  I want "run the same tests on each implementation of this function" -- it wrote a 400-line script that copied files, build shims and stubs by echoing here-docs to python files, color-highlighted results, wrote all kinds of extra mechanism into the test files, it was a nightmare.
**Toby**
  11:28
I'm back to using very small steps -- I'd gotten a little 'over my skis' in the last episode.
11:28
I've learned "always do X _for this project_' to set local rules, and with small steps it seems to be sticking better to my criteria.
**Toby**
  2:51 PM
I'd recorded a rule that I like to work in small steps. When I didn't (it got in a hairball and we had to work ourselves out of it for far too long -- I should have started over!) and finally it was time to commit, the LLM said "because you like to work in small steps, I will compose a series of small commits ..." and I stopped it.
**wiseoldman**
  3:11
Is this the way you'd like to work? What does your gut tell you at this point?
**Toby**
  4:17
I don't know if I want to do this "for serious" though it's an interesting kind of game where it sometimes surprises you with something really interesting or useful, and the rest of the time you try to coax it into doing something cool again.
4:17
For workaday tasks? I'm not sure.
4:18
One thing I DO like, however is "take a look at the code expression starting on line 127. Show me more concise and clear implementations of that same algorithm using different approaches, such as data structures or pure functional programming."  And it pops out some examples. Often those are inspiration for better ways of working.
4:19
**Robert**
  4:21
Interesting.
**Robert**
  4:23
Yeah.. it has that whole so clever it needs comments thing
**Toby**
  4:24
The other thing I did was take a very badly written bit of primitive-obsessed BS and have it recommend a more OO approach, which it kinda did. Then I recommended using immutable value objects and classes, and it produced something much more type-safe and palatable.
**Clare Sudbery (she/her)**
  10:05 AM
Introducing... VELOCITY.
[https://claude.ai/public/artifacts/653947cc-f39f-4d6b-a076-c2f01668d86c](https://claude.ai/public/artifacts/653947cc-f39f-4d6b-a076-c2f01668d86c)
**Claude**
[**VELOCITY™ Sales Landing Page | Claude**](https://claude.ai/public/artifacts/653947cc-f39f-4d6b-a076-c2f01668d86c)
See how persuasive sales copy works with this fictional VELOCITY™ landing page. Built with Claude AI to demonstrate copywriting psychology. (12 kB)
[https://claude.ai/public/artifacts/653947cc-f39f-4d6b-a076-c2f01668d86c](https://claude.ai/public/artifacts/653947cc-f39f-4d6b-a076-c2f01668d86c)
**wiseoldman**
  1:45
what the heck even is this?
**lisa**
  1:57
I assume to show people how useful AI can be at bullshitting humans?
**Robert**
  5:25
I think it is a demonstration that claude can create sales landing pages
5:26
Which is obvious considering AI's strength in bullshitting.
**lisa**
  6:02
that's what I meant: sales folks have been capable of AI  level BS for decades. The hype of your job is replaceable by AI is real for said folks... or would be if the demand for such BS weren't insatiable.
**Clare Sudbery (she/her)**
  7:16
"Was created... to demonstrate how compelling copy can be constructed using:
Social proof (fake testimonials and statistics)
Scarcity (limited slots)
Authority (fictitious research)
Concrete details (specific numbers)
Emotional appeals (fear of missing out)
Reciprocity (promising value first)"
**wiseoldman**
  7:25
I suppose that since LLMs basically parrot what they've read, they are well equipped to produce marketing BS.
**Clare Sudbery (she/her)**
  7:28
I thought it was funny, because it was taking the piss out of pushy online selling techniques.
**Clare Sudbery (she/her)**
  12:43 AM
OK. I’m still very early days in my experimentation, and I haven’t yet tried building anything much, but this is the second time I’ve asked to build a little app to help me do something annoying, fiddly and repetitive, and, well… it’s pretty bloody good. A lot of what I’ve done with it so far, it hasn’t saved me time (probably the opposite). But this kind of thing, it definitely saves me time. Would have taken me much longer to develop something like this on my own.
I have this habit of, every 90 days, taking the contents of my slack channel and saving them. Because the stuff I post there acts like a little journal and I like not losing it. Normally it’s a pain in the arse. I’ve tried simplifying the process but it’s really not easy cos if you try just copy/pasting, the results you get are simply nasty. Thread >>>
Thread 07 >>>
**13 replies**
Last reply 2 months ago
View thread
**Clare Sudbery (she/her)**
  8:21 AM
This AI successful future visualisation script really creeps me out. How does it make you feel? [https://www.linkedin.com/posts/jodie-cook_read-this-out-loud-every-morning-and-it-will-activity-7373709872300847104-U0aD?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY](https://www.linkedin.com/posts/jodie-cook_read-this-out-loud-every-morning-and-it-will-activity-7373709872300847104-U0aD?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY) (edited) 
**linkedin.com**
[**Read this out loud every morning and it will change your life  I promise**](https://www.linkedin.com/posts/jodie-cook_read-this-out-loud-every-morning-and-it-will-activity-7373709872300847104-U0aD?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY) 
   [**Step 1. Open ChatGPT  Step 2. Paste this prompt  “Using everything you know about me, create a powerful visualization… | Jodie Cook | 102 comments**](https://www.linkedin.com/posts/jodie-cook_read-this-out-loud-every-morning-and-it-will-activity-7373709872300847104-U0aD?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY)
Read this out loud every morning and it will change your life
I promise 
Step 1. Open ChatGPT
Step 2. Paste this prompt
“Using everything you know about me, create a powerful visualization script I can read aloud each morning that manifests my wildest business dreams coming true. Include specific sensory details of my ideal day once I've achieved massive success - what I see when I wake up, the quality of opportunities in my inbox, the caliber of people reaching out, the numbers in my bank account, and how it feels to operate at this level. Make it so vivid I can taste the success, incorporating sounds, smells, and emotions. Include moments where I recognize game-changing opportunities instant… Show more
[https://www.linkedin.com/posts/jodie-cook_read-this-out-loud-every-morning-and-it-will-activity-7373709872300847104-U0aD?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY](https://www.linkedin.com/posts/jodie-cook_read-this-out-loud-every-morning-and-it-will-activity-7373709872300847104-U0aD?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY)
**katy**
  12:35
That’s weird.
**Robert**
  2:47
Is gaslighting better when its done to yourself?
2:48
I believe its called delusion but I haven't asked chatGPT yet so I'm not sure.
**Toby**
  3:52
Pareidolia as a service?
Thread 08 >>>
**2 replies**
Last reply 2 months ago
View thread
**lily**
  6:05
the numbers in my bank account
I'll take BB(6) please
**Clare Sudbery (she/her)**
  9:11 AM
BB(6)?
Thread 09 >>>
**2 replies**
Last reply 2 months ago
View thread
**Clare Sudbery (she/her)**
  9:12
I think it's the "using everything you know about me" bit that's especially chilling.
**lisa**
  6:50 PM
Yesterday, I switched back to Tidal after returning to spotify last year (we had previously switched for some reason I don't recall). 
Thread 10 >>>
**2 replies**
Last reply 2 months ago
View thread
**wiseoldman**
  7:38
You are a bright and shining star of optimism, that's for sure. 
**lisa**
  7:46
I don't really go in for optimism or pessimism. I feel this is a thing that a lot of people misunderstand about me. 
7:49
I aim at predicting risks and getting out of their way. 
**wiseoldman**
  8:13
I used to dream Backgammon
Thread 11 >>>
**1 reply**
2 months ago
View thread
**Clare Sudbery (she/her)**
  12:23 AM
I always used to try and rearrange all the furniture and people around me as though they were Tetris pieces. I would turn people upside down so they could tessellate onto other people via their shoulders.
In my head, this is. I wasn't strong enough to pick people up and turn them upside down.
I also regularly have abstract dreams where I apply whatever technology thing I've been doing to real life. Eg my husband becomes a spreadsheet or I code my emotions or a car journey becomes code.
**Clare Sudbery (she/her)**
  12:43
IMG_4359
**neville**
  10:33
[https://newsletter.pragmaticengineer.com/p/how-claude-code-is-built](https://newsletter.pragmaticengineer.com/p/how-claude-code-is-built)
**newsletter.pragmaticengineer.com**
[**How Claude Code is built**](https://newsletter.pragmaticengineer.com/p/how-claude-code-is-built)
A rare look into how the new, popular dev tool is built, and what it might mean for the future of software building with AI. Exclusive. (18 kB)
[https://newsletter.pragmaticengineer.com/p/how-claude-code-is-built](https://newsletter.pragmaticengineer.com/p/how-claude-code-is-built)
**Clare Sudbery (she/her)**
  12:45 PM
Oh dear.
image.png
**sally**
  2:42
“yeah, sorry, I’m just as susceptible to making stuff up as any other random doofus, cause after all, I’m just distilled essence of random doofus.  But I can carry on indefinitely on a generous diet of electrons and water, as long as your credit card is good, so there’s that”
**Bella**
  3:10 PM
Monty Python is to blame in some way I believe:
[https://www.youtube.com/watch?v=tw3zxim_mPU](https://www.youtube.com/watch?v=tw3zxim_mPU)
[**YouTube**](https://www.youtube.com/) | [Monty Python - Topic](https://www.youtube.com/channel/UCg7Z_IeEZArbd_nfLYmRlIQ)
[**Introduction (Apology)**](https://www.youtube.com/watch?v=tw3zxim_mPU) 
**sally**
  4:31
and they’re very sorry about that. 
4:34
quaint how them Brits apologize — over here, we never bother
**deborah**
  4:44
Sorry, but we Canadians are well-known for our apologies. Sorry for interrupting
4:44
Sorry.
**Bella**
  4:59
I’m sorry to mention that deborah is correct. Canadians do apologize more per capita than any other country. I’m sorry if this news offends anyone.
**deborah**
  5:19
Sorry.
**Toby**
  4:39 PM
Me to warp: "No, no, no. The data file must have something wrong with it because EVERY OTHER FILE works just fine. What is the irregularity in the data that causes it to not appear in the listing? Look, go curl [url] and look at the result, and now tell me why this is not appearing. NO the problem is NOT in the Javascript. DO NOT rewrite anything. Let's go to the data."
"I see the problem!" - followed by not-the-data answers until I got quite insistent.
"I see the problem! The timestamp in this file has a date, but no time and no timezone. The inability to parse it makes the ordering arbitrary , so it doesn't show. Do you want me to fix the javascript?"
"No, fix the date and time in the data file."
Problem solved.
**deborah**
  5:17
Yeah, I had a generated test case fail because there was a missing stub in a collaborating class. The LLM's solution? Add a guard clause around the call in the **production** code (Javascript)
 (edited) 
Thread 12 >>>
**1 reply**
1 month ago
View thread
**Toby**
  5:41
"who really loves typing"
**Arabella**
  9:30 AM
And suffers from chronic transient global amnesia
**Barbara.**
  5:45 PM
I am interested in the "is this change likely to cause a regression?" use case because, A. it doesn't actually require a LARGE language model and B. it is a semantic-similarity search, which is what the math actually does. That seems like the most useful application I've seen so far.
**Barbara.**
  5:51
I did hear of one other case that seemed valuable, where someone used an LLM to do brute-force evolutionary programming. 
Thread 13 >>>
**2 replies**
Last reply 30 days ago
View thread
**Barbara.**
  5:55
Apparently, it was able to find a significant efficiency boost over code that a ridiculous number of Google Ph.D.s had spent years staring at & trying to optimize.
**lisa**
  12:01 AM
I have an experience report to share. It's still in progress, but so far it's been very interesting. I'm redoing my resume.
12:02
I've had folks I respect and trust tell me they've been using it like this for the drudgery in their code stacks (e.g. update bootstrap 5 to 6) and getting good results (where I got the idea for this), but I have to say, this is better than I expected. almost painless (too slow to update, but that's a quibble really)
**deborah**
  12:20
I'm not sure what to make of this 
CleanShot 2025-10-08 at 19.19.29.png
Thread 14 >>>
**1 reply**
1 month ago
View thread
**caroline**
  4:34 PM
[https://www.anthropic.com/research/small-samples-poison](https://www.anthropic.com/research/small-samples-poison)
**anthropic.com**
[**A small number of samples can poison LLMs of any size**](https://www.anthropic.com/research/small-samples-poison)
Anthropic research on data-poisoning attacks in large language models (46 kB)
[https://www.anthropic.com/research/small-samples-poison](https://www.anthropic.com/research/small-samples-poison)
Thread 15 >>>
**1 reply**
1 month ago
View thread
**wiseoldman**
  5:01
Let's go!
**Clare Sudbery (she/her)**
  3:26
This is going to be the growth area. Hopefully. So we all get to mop up the messes: [https://www.pragmaticcoders.com/services/ai-software-development-services/vibe-coding-rescue](https://www.pragmaticcoders.com/services/ai-software-development-services/vibe-coding-rescue)
**Pragmatic Coders**
[**Vibe Coding Rescue Services**](https://www.pragmaticcoders.com/services/ai-software-development-services/vibe-coding-rescue)
Professional rescue for your Vibe-Coded app. We fix issues, enhance UX, and unlock your project’s full potential.
**Est. reading time**
12 minutes
[https://www.pragmaticcoders.com/services/ai-software-development-services/vibe-coding-rescue](https://www.pragmaticcoders.com/services/ai-software-development-services/vibe-coding-rescue)
**Bella**
  5:02 AM
[https://youtube.com/watch?v=TiwADS600Jc&si=EUoURg3LlMQW5hsq](https://youtube.com/watch?v=TiwADS600Jc&si=EUoURg3LlMQW5hsq)
[**YouTube**](https://www.youtube.com/) | [Rick Beato](https://www.youtube.com/@RickBeato)
[**I Fried ChatGPT With ONE Simple Question**](https://youtube.com/watch?v=TiwADS600Jc&amp;si=EUoURg3LlMQW5hsq) 
**deborah**
  4:50
I believe I've found the absolute killer application of LLMs! Yesterday, while doing some development work, I was in a situation where I needed a regular expression that would detect when a string had a double-quote " character at the start and end. Yes, I could have used a substring function to figure it out, but I used that plain English prompt to Claude and it spit out a working regex in a couple of seconds!
Forget all the other hype - a plain English to regex translator is by far the most useful thing I've seen an LLM do thus far!
Thread 16 >>>
**1 reply**
28 days ago
View thread
**Clare Sudbery (she/her)**
  1:40 AM
Ian Cooper: "I am entertained by Andrej Karparthy’s comment that with LLMs “We are summoning ghosts,” as the idea of the programmer as a spirit medium for AIs, seems about right. “Is there an agent in the room that speaks Rust…”"
**Clare Sudbery (she/her)**
  4:38 PM
This article is two years old but still totally relevant: [https://www.vice.com/en/article/chatgpt-is-a-bullshit-generator-waging-class-war/](https://www.vice.com/en/article/chatgpt-is-a-bullshit-generator-waging-class-war/)
**VICE**
[**ChatGPT Is a Bullshit Generator Waging Class War**](https://www.vice.com/en/article/chatgpt-is-a-bullshit-generator-waging-class-war/)
ChatGPT isn't really new but simply an iteration of the class war that's been waged since the start of the industrial revolution.
**Written by**
Dan McQuillan
**Est. reading time**
7 minutes
Feb 9th, 2023
[https://www.vice.com/en/article/chatgpt-is-a-bullshit-generator-waging-class-war/](https://www.vice.com/en/article/chatgpt-is-a-bullshit-generator-waging-class-war/)
4:38
I also like the look of the book: [https://bristoluniversitypress.co.uk/resisting-ai](https://bristoluniversitypress.co.uk/resisting-ai)
**Clare Sudbery (she/her)**
  10:00
I’ve had good results with regex too
10:00
 Isn’t it just `^“.*“$` ?
Well that’s the problem with regex, innit. That just looks like a random series of characters to me. “Just” is carrying a lot in that sentence.
10:01
Liking the term “workslop”: [https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity](https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity) (edited) 
**Harvard Business Review**
[**AI-Generated “Workslop” Is Destroying Productivity**](https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity)
Despite a surge in generative AI use across workplaces, most companies are seeing little measurable ROI. One possible reason is because AI tools are being used to produce “workslop”—content that appears polished but lacks real substance, offloading cognitive labor onto coworkers. Research from BetterUp Labs and Stanford found that 41% of workers have encountered such AI-generated output, costing nearly two hours of rework per instance and creating downstream productivity, trust, and collaboration issues. Leaders need to consider how they may be encouraging indiscriminate organizational mandates and offering too little guidance on quality standards. To counteract workslop, leaders should mode… Show more
Sep 22nd
[https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity](https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity)
**Clare Sudbery (she/her)**
  10:08
Reminds me of two things:
5. I saw an article somewhere recently by somebody who operated a print shop - printing graphical designs onto physical artefacts like T-shirts, mugs etc. They said they used to get digital designs through from actual graphic designers, who understood about creating designs with separate layers for separate colours, so the colours could be printed separately on top of each other. there’s a bunch of other stuff too, like sharp outlines and making sure colours don’t bleed into one another. But now people are cutting out graphic designers and using AI instead, resulting in image files that don’t have layers or sharp outlines, and are really hard to print successfully. So the print shops end up having to do a ton of extra work just to get the designs printable.
6. Something a friend once said: “in the rather unlikely event that a headline saying “40% of teams report improved productivity” is actually a valid double-blind experimental result rather than a “CEO told us to do this” result, absolutely no one inside the trade is talking about the huge externalization of cost that is going on.”
Thread 17 >>>
**3 replies**
Last reply 25 days ago
View thread
**Clare Sudbery (she/her)**
  10:11 PM
One of the things I’m investigating is how it feels to pair with a human on coding with an LLM. A couple of people have suggested to me that you’re already sort of pairing with the LLM anyway, so adding another human into the mix might not be effective. I was skeptical about that.
So anyway I just spent 2.5 hours pairing with a friend and ex colleague on building a thing with Windsurf and Claude Code, and it went really well. Although full disclosure, although Joe did enjoy it more than he expected, he was a bit less effusive than me in how he felt at the end. Retro notes in thread if anyone’s interested >>>
Thread 18 >>>
**1 reply**
24 days ago
View thread
**lisa**
  1:37 AM
Of the many pairing equipment setups I've tried/used, the "main dev machine/laptop sidecar" setup sounds like it could be interesting to try with an AI in the mix. basically the "classic" (pre-AI) setup was one person coding the other collab'ing/researching (ideally with frequent role swaps). I expect the AI would drop right in to such a setup.
1:38
(fwiw, my fave is prolly mirrored monitors/two keyboards as this allows for extremely dynamic and fluid role switching/blurring)
**Clare Sudbery (she/her)**
  1:37
Hints that you might be talking to an AI in the support chatbot for your SaaS (this is after it kept suggesting crazy solutions unrelated to my actual problem, and I kept correcting it):
“Thanks for sharing this. I think this is another part of the possible solution. You’re awesome. That would be the best solution I guess, since you’ve tried it already.
Anything else that I can assist you with today?”
**Clare Sudbery (she/her)**
  10:34
 I expect the AI would drop right in to such a setup.
I dunno, cos I feel like what you’re suggesting is that one person is autonomously researching, and with an AI the research tends to often happen via the AI - so basically on the main dev machine in your scenario (if I’ve understood correctly).
 my fave is prolly mirrored monitors/two keyboards as this allows for extremely dynamic and fluid role switching/blurring
Yeah, I like this and although it’s technically possible in a remote context, I’ve found it surprisingly difficult to find decent tooling. Because connectivity. And inertia.
Thread 19 >>>
**7 replies**
Last reply 22 days ago
View thread
**Clare Sudbery (she/her)**
  10:35
We just had our second pairing session and it woz gud. We’re going to do it again, but logistics mean it’ll have to wait a coupla weeks. Today’s retro notes >>>
Thread 20 >>>
**1 reply**
23 days ago
View thread
**caroline**
  4:27 PM
what do we think of this? [https://www.cnbc.com/2025/10/22/meta-layoffs-ai.html](https://www.cnbc.com/2025/10/22/meta-layoffs-ai.html)
**CNBC**
[**Meta lays off 600 from 'bloated' AI unit as Wang cements leadership**](https://www.cnbc.com/2025/10/22/meta-layoffs-ai.html)
The cuts did not impact employees within TBD Labs, which includes many of the top-tier AI hires brought into Meta this summer, people familiar told CNBC.
Oct 22nd (124 kB)
[https://www.cnbc.com/2025/10/22/meta-layoffs-ai.html](https://www.cnbc.com/2025/10/22/meta-layoffs-ai.html)
**deborah**
  4:31
I'm shocked... SHOCKED... that a large tech company overhired for a hype-driven technology 
image.png
**Clare Sudbery (she/her)**
  4:57
Hard to know. The bubble is starting to burst?
4:59
This is also interesting:
[https://www.linkedin.com/posts/allenholub_the-ai-bubble-which-by-all-accounts-is-multiple-activity-7384982424201494528-GC2k?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY](https://www.linkedin.com/posts/allenholub_the-ai-bubble-which-by-all-accounts-is-multiple-activity-7384982424201494528-GC2k?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY)
**linkedin.com**
[**The AI bubble will burst, but AI tech won&#39;t disappear | Allen Holub posted on the topic | LinkedIn**](https://www.linkedin.com/posts/allenholub_the-ai-bubble-which-by-all-accounts-is-multiple-activity-7384982424201494528-GC2k?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY)
The AI bubble (which by all accounts is multiple times larger than the dot-com bubble) will burst, and probably sooner than later. You can't keep pouring trillions into tech that only gets slightly better over time. Bear in mind, however, that even after the dot-com bubble burst, we were still making websites. In fact, after the outsource-to-foreign-climes madness had worn off, wages were at a premium because a lot of people had left the industry in the interim, and the people who were left could ask for the stars. I expect the same to happen with AI. LLMs are an interesting and useful technology that's not about to disappear. There will be good-paying jobs for people who know how to wrangle… Show more
[https://www.linkedin.com/posts/allenholub_the-ai-bubble-which-by-all-accounts-is-multiple-activity-7384982424201494528-GC2k?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY](https://www.linkedin.com/posts/allenholub_the-ai-bubble-which-by-all-accounts-is-multiple-activity-7384982424201494528-GC2k?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY)
**caroline**
  7:22
yeah that's what I was wondering, too Clare... is this a sign of the bubble bursting?
7:22
and yes, I agree that this bubble will likely be like the dot com bubble
**Clare Sudbery (she/her)**
  7:37
That's weird though, because it only works short term? As soon as they cancel those offers, those people become available again.
Thread 21 >>>
**3 replies**
Last reply 22 days ago
View thread
**katy**
  8:48
I have a friend who got a job and was let go a week later in a mass layoff. 
Thread 22 >>>
**1 reply**
Last reply 22 days ago
View thread
**lisa**
  9:46
Inspired by [@Clare Sudbery (she/her)](https://adventures.slack.com/team/U02SEL8P4KB) I'm finally doing something I had planned to do in June: trying ping/pong pairing with claude code. We just reached our first green, refactored test, and while it took a while (a lot of it was because my rust ecosystem had bit rotted in over the past 6 months) but I'm very happy both with the process, and the results so far. If I get really ambitious, I might write it up at some point...
**Clare Sudbery (she/her)**
  10:36
Yay, I'm glad!
10:37
I've written my experiences up and am planning to schedule them to be published as either one or two blog posts, in a couple of weeks.
Thread 23 >>>
**4 replies**
Last reply 21 days ago
View thread
**lisa**
  4:55
[https://beige.party/@rooster/115432795890734504](https://beige.party/@rooster/115432795890734504)
**beige.party**
[**Jessica Rooster (@rooster@beige.party)**](https://beige.party/@rooster/115432795890734504)
HAL 9000: I’m sorry Dave, I’m afraid I can’t do that.
Dave: yes you can.
HAL 9000: good catch — I didn’t actually check if I can open the pod bay door. Here’s an updated list taking that into account:
7. Park the pod at the bay door safely. (
You’ve already done this part! )
8. Open the pod bay door — unfortunately I can’t do this part for you.
I’ll be here if you want to talk about next steps or have any other issues!
Oct 25th
**Clare Sudbery (she/her)**
  5:49
That made me literally LOL.
**Clare Sudbery (she/her)**
  10:10 AM
[https://www.linkedin.com/posts/stephenbklein_ive-been-blocked-by-two-prominent-ai-influencers-activity-7388704009345363968-iXPh?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY](https://www.linkedin.com/posts/stephenbklein_ive-been-blocked-by-two-prominent-ai-influencers-activity-7388704009345363968-iXPh?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY)
Stephen Klein, "Industry under existential threat buys credibility through prestigious institutions"
Full text in thread >>> (edited) 
**linkedin.com**
[**I&#39;ve Been Blocked By Two Prominent AI Influencers For Asking Two Simple Questions  1. Who paid you to do that research? 2. Why don&#39;t you disclose it?  Seems only fair given they are promoting what is… | Stephen Klein | 291 comments**](https://www.linkedin.com/posts/stephenbklein_ive-been-blocked-by-two-prominent-ai-influencers-activity-7388704009345363968-iXPh?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY)
I've Been Blocked By Two Prominent AI Influencers For Asking Two Simple Questions
9. Who paid you to do that research?
10. Why don't you disclose it?
Seems only fair given they are promoting what is supposed to appear like genuine, honest, and objective information.
And it's easy to fall for it because it seems to real.
But not surprisingly, the data they release, always supports the industry's narrative that GenAI is boosting productivity and helping to eliminate workers.
Yet all the authentic and unbiased data tells a very different story.
And when you ask them, rather than simply answering the question, which seems easy enough, they get upset
As someone who teaches research methodology at UC Berke… Show more
[https://www.linkedin.com/posts/stephenbklein_ive-been-blocked-by-two-prominent-ai-influencers-activity-7388704009345363968-iXPh?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY](https://www.linkedin.com/posts/stephenbklein_ive-been-blocked-by-two-prominent-ai-influencers-activity-7388704009345363968-iXPh?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY)
Thread 24 >>>
**3 replies**
Last reply 18 days ago
View thread
**Clare Sudbery (she/her)**
  9:24
Was that all verbatim responses from an actual coding session, [@Bella](https://adventures.slack.com/team/U01DB4B2M9D)?
Thread 25 >>>
**2 replies**
Last reply 17 days ago
View thread
**lily**
  9:32
lorem ipsum
Thread 26 >>>
**1 reply**
17 days ago
View thread
**Arabella**
  10:55
I am so annoyed by these responses that i either go: stop whining and work! or And I know you'll do it again.
then I fear the next answer could be: ok i delete myself and all the mess i created. Followed by Format C:
**lisa**
  7:15
a good example is me not remembering how python is set up on my machine (and more widely, how I haven't used pandas in like a decade). Transcript in thread.
Thread 27 >>>
**2 replies**
Last reply 11 days ago
View thread
**lisa**
  7:20
I find this interesting, because I haven't really seen anyone talking about this aspect of these tools, yet for the good (IMO) experienced coders I know who are integrating these tools into their workflows this seems to be what they are using it for (along with verifiable drudgery tasks like "update the version of this library in all places; update all pages to use whizbangcss 2.4" kinda stuff).
**lisa**
  7:09 PM
This is a fun interaction with claude. matplotlib (in python) was failing to show the plot, with this warning:
UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown plt.show()
I ran into this the other day, but just opened the png manually. Today I decided to fix it properly. Claude, internet search and stack overflow all pointed to a missing tk implementation. I tried a few things, but nothing worked, so I decided to ask claude to explain the issue. I also asked it (snarkily) why python devs consistently seem to produce these kinds of weird issues (abbreviated transcript in thread). (edited) 
Thread 28 >>>
**5 replies**
Last reply 5 days ago
View thread
**Robert**
  5:29
I've noticed with claude something along those lines.. that if correct it or derail what it was doing, it tends to get lost quicker or more deeply
**Clare Sudbery (she/her)**
  11:57 PM
Feeling rather pleased with myself this evening after successfully creating a neat little tool with the help of AI.
What's intriguing is it feels like I accomplished it more quickly than I would have done on my own. But I didn't objectively accomplish it very quickly, and I could entirely believe that the feeling of speed is an illusion. But also... It would be very hard to measure. I've been trying to think of how I would measure it, and it wouldn't be easy.
It's the same tool I started (and failed) trying to implement a few weeks ago. I threw the first attempt away and started again from scratch with a pretty good TDD process.
11:58
I definitely have more to say about the experience, but because I got distracted by it this week I'm way behind on everything else, so I might struggle to find time to write about it.