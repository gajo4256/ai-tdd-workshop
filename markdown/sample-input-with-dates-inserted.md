
## Fri 12/09/2025

**Clare Sudbery (she/her)**
  2:03 PM
Here’s a great example of “AI” being used SO poorly:
We needed to call the 24-hr breakdown people while away from home, to fix broken brakes. We were in a remote hilltop location, very little phone reception or wifi. The way to call them was via an app. Booking the initial appt was fine, but then I wanted to update them with a better description of my hard-to-find location. I knew they wouldn’t be able to ring me. The _only_ way I could contact or update them was by being taken out to WhatsApp via a button in the app, where I was chucked out, with no context, to talk to an AI bot. It took me half an hour to even get into WhatsApp, because they insisted I update the app, which took half an hour because poor wifi.
This is the conversation which then ensued (in thread).
Luckily the mechanic was EXCELLENT. It’s a shame I can’t say the same for the app. >>> (edited) 
Thread 01 >>>
**1 reply**
Clare Sudbery (she/her)  Aug 22nd at 2:05 PM  
ME, 12:40:  
Hi  
**We are at Bimble Cottage, Bimbletown, Bimbleshire LMXX XXX**
AA, 12:40:  
Thanks for choosing to contact us on WhatsApp.  
Unfortunately, we’ve hit a bit of a speed bump and some of our teams are currently unavailable. So it may take longer than usual for us to get back to you, but one of our team will reply as soon as they’re free. We’ll pick up messages sent outside our opening hours on the next working day.  
If you’re happy to wait, tell me what you need help with today and I’ll get you moving in the right direction. Or feel free to come back another time.  
To learn how the AA handles your personal data, see our privacy notice at https://www.theaa.com/privacy-notice[.](https://www.theaa.com/privacy-notice.)  
*AA Bot*  
I didn’t quite catch that - your message may be too long for me to understand.  
Try sending a short sentence under 10 words to summarise the help you need. Or type ‘menu’ for a list of topics to get you started.
ME, 12:40:  
**Location update for rescue: Bimble Cottage, Bimbletown, Bimbleshire LMXX XXX**
AA, 12:40:  
*AA Bot*  
Sorry, I’m still learning certain phrases. You can rephrase your query and let me try again, or type ‘menu’ for a list of topics to narrow down your query.
ME, 12:41:  
**We are waiting for a rescue and want to update our location**
AA, 12:41:  
*AA Bot*  
I’m having some trouble understanding. Not to worry - I’ll add some options below for you to pick from.  
If you can’t find one that fits, head to our Help and Support page for more contact options: https://www.theaa.com/help-support  
Pick an option that best describes what you need help with and I’ll get you through to someone.  
Tap the button below to see options.
ME, 12:41:  
Breakdown cover
AA, 12:41:  
How did you get your breakdown cover?  
Tap the button below to see options.
ME, 12:41:  
Directly from The AA
AA, 12:41:  
*AA Bot*  
Thanks, I just need to ask you a few questions before I can bring up your information.  
*AA Bot*  
What’s your first name?
ME, 12:41:  
ClareAA, 12:41:  
*AA Bot*  
What’s your last name?
ME, 12:41:  
SudberyAA, 12:42:  
*AA Bot*  
What’s your email address?
ME, 12:42:  
[my email address]
AA, 12:42:  
*AA Bot*  
What’s your postcode?  
For example: RG214EA
ME, 12:42:  
[my home postcode]
AA, 12:42:  
*Did you buy your policy in the last 24 hours?*
ME, 12:42:  
No
AA, 12:42:  
What type of policy do you have?  
Tap the button below to see options.
ME, 12:42:  
Cover with The AA
AA, 12:42:  
*AA Bot*  
What’s your membership number? This is a 16 digit number beginning with ‘6356’.
ME, 12:43:  
[my mbr num but with spaces, which is how they display it, like this: xxxx xxxx xxxx xxxx]
AA, 12:43:  
*AA Bot*  
Sorry, I didn’t recognise that. Please make sure the membership number you enter has 16 digits. You’ll find this on your membership card or policy documents.  
*AA Bot*  
What’s your membership number? This is a 16 digit number beginning with ‘6356’.
ME, 12:43:  
[same again but spaces removed: xxxxxxxxxxxxxxxx]
AA, 12:43:  
*AA Bot*  
Thanks. I’ll get you over to a member of our team to carry on with the conversation.  
Someone will be with you shortly.  
They’ll look into your query and get back to you as soon as they can – right here in this chat. You can then reply here too whenever it’s convenient for you.
ME, 12:44:  
**I’m waiting for recovery and all I’m trying to do is make sure you know the address of our location!**  
**It’s Bimble Cottage, Bimbletown, Bimbleshire LMXX XXX**
AA, 12:59:  
*Sharon*  
Hi there! I’m Sharon, and I’ll be assisting you today. Please remain connected so I can ensure your request is properly handled. While I access your profile and review your request do you have any additional queries regarding your membership?
ME, 13:00:  
No
AA, 13:03:  
*Sharon*  
Hello, thankyou for contacting The AA, are you in a safe location?
ME, 13:04:  
Yes  
**I’m waiting for recovery and all I’m trying to do is make sure you know the address of our location!**  
**It’s Bimble Cottage, Bimbletown, Bimbleshire LMXX XXX**
AA, 13:04:  
*Sharon*  
I hope you have, reported the breakdown with us?
ME, 13:05:  
Yes!  
**It’s ok he’s just arrived** (edited)
3 months ago
View thread
**wiseoldman**
  2:42
bril.
**neville**
  3:45
at my client, there's been a big push for using AI tooling -- plusses & minuses, but a funny thing happened yesterday 
Thread 02 >>>
**2 replies**
**neville**
  Aug 22nd at 3:46 PM
Screenshot 2025-08-22 at 10.44.17 AM.png
3:47
Screenshot 2025-08-22 at 10.46.43 AM.png
3:47
i think people are forgetting (or never learning?) how to do things...
**lisa**
  Aug 22nd at 3:53 PM
Last reply 3 months ago
View thread
**Clare Sudbery (she/her)**
  8:59
[deep breath]
I have a confession to make.
I’ve been paying close attention to all things genAI-coding-related for several months now. I suspect I’m not alone in being torn between “OMG this AI nonsense is messing the world up generally and my industry specifically”, and “OMG how am I going to survive in this industry if I don’t at least _look_ at this thing” and “OMG this might actually be useful in _some_ ways, at least” and “OMG what shall I teach next?”
Net result: I did the following…
1. Started collecting articles and links and resources about genAI coding, with a vague plan to use my explainy skills to help people understand what the hell is happening
2. Started thinking about experimenting with genAI coding, using a small language model
3. Remembered that the easiest way for me to learn / explore anything is to (a) give myself a real-world deadline, and (b) aim to teach it to others
4. Pitched a “combining AI and TDD” workshop to Software Architecture Gathering in Berlin.
Further consequence: I’m now torn between guilt and self loathing for making a pact with the devil, and excitement at learning / playing with something new.
**sally**
  9:49
Seems sensible all around
**wiseoldman**
  10:47
I followed my nose on a couple of google searches, with interesting results, as mentioned above. I used TDD style tests to check the things, to convert them to a form I wanted, and to embed them into the objects I was creating. I think you'll find things to talk about.
Aug 26th

## Sat 27/09/2025

**Clare Sudbery (she/her)**
  9:54 PM
Ooof. I just spent 2.5 days (specifically, 15 hrs and 20 mins) (I know because I’m anal like that and have spreadsheets) watching ONE VIDEO and making notes.
The video in question was Llewellyn Falco’s talk at May’s Craft Conf about using process files when coding with AI. I made _copious_ notes (cos that’s also what I do) (when I have time) (yay for time! I'm making the most of it while it lasts) and I feel good about that. Even though I feel like I wasn’t very efficient*, I’m happy and I enjoyed the process.
Anyway, if anyone’s interested, links in thread - to the source material, and to my notes. 
Thread 03 >>>
**8 replies**
**Clare Sudbery (she/her)**
  Aug 27th at 9:58 PM
The video is [here](https://youtu.be/MMqahx1PRQo?si=mHcIf8Ghn5fjFmNm).
[**YouTube**](https://www.youtube.com/) | [CraftHub Events](https://www.youtube.com/@crafthub.events)
[**Process files: Blueprints for Agentic AI - Llewellyn Falco | Craft 2025**](https://youtu.be/MMqahx1PRQo?si=mHcIf8Ghn5fjFmNm) 
9:58
---
The code Llewellyn was working with is [here](https://github.com/LearnWithLlew/AgenticAi.Java.StarterProject/tree/craft-2025). (edited) 
**GitHub**
[**GitHub - LearnWithLlew/AgenticAi.Java.StarterProject at craft-2025**](https://github.com/LearnWithLlew/AgenticAi.Java.StarterProject/tree/craft-2025)
Contribute to LearnWithLlew/AgenticAi.Java.StarterProject development by creating an account on GitHub. (56 kB)
[https://github.com/LearnWithLlew/AgenticAi.Java.StarterProject/tree/craft-2025](https://github.com/LearnWithLlew/AgenticAi.Java.StarterProject/tree/craft-2025)
9:58
---
It’s not the code that’s interesting though (there wasn’t much of it), it’s the [process files](https://github.com/LearnWithLlew/AgenticAi.Java.StarterProject/tree/b5c08c13cb052c69f3e8d89c817e2e3638f07315/.windsurf/processes) - which were the point of the talk. (edited) 
**GitHub**
[**AgenticAi.Java.StarterProject/.windsurf/processes at b5c08c13cb052c69f3e8d89c817e2e3638f07315 · LearnWithLlew/AgenticAi.Java.StarterProject**](https://github.com/LearnWithLlew/AgenticAi.Java.StarterProject/tree/b5c08c13cb052c69f3e8d89c817e2e3638f07315/.windsurf/processes)
Contribute to LearnWithLlew/AgenticAi.Java.StarterProject development by creating an account on GitHub. (56 kB)
[https://github.com/LearnWithLlew/AgenticAi.Java.StarterProject/tree/b5c08c13cb052c69f3e8d89c817e2e3638f07315/.windsurf/processes](https://github.com/LearnWithLlew/AgenticAi.Java.StarterProject/tree/b5c08c13cb052c69f3e8d89c817e2e3638f07315/.windsurf/processes)
9:59
---
My notes are [here](https://publish.obsidian.md/clare-wiki-career/Clare's+Career/0+-+Missions/09-AI-Mission/AI+people/Llewellyn+Falco/Llewellyn+Falco#Contents+of+this+file). Not actually sure how useful they are to anyone except me - you’re probably better off just watching the video - but I’ve just added a ToC and some summaries that make them slightly more useful I think. (edited) 
**publish.obsidian.md**
[**Llewellyn Falco - Obsidian Publish**](https://publish.obsidian.md/clare-wiki-career/Clare's+Career/0+-+Missions/09-AI-Mission/AI+people/Llewellyn+Falco/Llewellyn+Falco#Contents+of+this+file)
Contents of this file Video about process files Useful links / resources Background What this means How we can use agentic AI effectively A demo Summary of demo Demo intro Step by step description of… (48 kB)
[https://publish.obsidian.md/clare-wiki-career/Clare's+Career/0+-+Missions/09-AI-Mission/AI+people/Llewellyn+Falco/Llewellyn+Falco#Contents+of+this+file](https://publish.obsidian.md/clare-wiki-career/Clare's+Career/0+-+Missions/09-AI-Mission/AI+people/Llewellyn+Falco/Llewellyn+Falco#Contents+of+this+file)
**elaine**
  Aug 27th at 11:50 PM
Efficient != Fast
**sally**
  Aug 27th at 11:58 PM
Your notes were really interesting and useful.  I’ll be going through this in the near future for an experiment—thanks!
**Clare Sudbery (she/her)**
  Aug 28th at 1:45 AM
Great, I'm glad they were useful!
**Toby**
  Aug 28th at 12:18 PM
heh "efficient" -- I suppose you were very efficient in extracting the maximum value from the presentation. Someone who glossed over it at double-speed while playing video games would be faster, but would not have efficiently extracted value.
**Toby**
  Aug 28th at 12:27 PM
Sharing templates, prompts, and process files is the new community activity.
**Clare Sudbery (she/her)**
  Aug 28th at 12:43 PM
Yes!
12:45
I don’t equate speed with efficiency, but I do wonder whether 2.5 days on one video and writing obsessively detailed notes was the best use of my time, and whether the value I extract will be worth the effort expended.
What I have to remind myself is that there were a lot of side quests, a lot of related notes, and now not _only_ do I have a detailed understanding of exactly how Llewellyn gets value from process files and scripts, I have a bunch of other useful stuff too.
**Clare Sudbery (she/her)**
12:56
What tools are people here using? Llewellyn uses Windsurf with four different AI agents - GPT, Gemini, Claude and SWE - but in the demo he stuck with GPT, with a little Gemini at the end for his daily status report. (edited) 
**Toby**
  Aug 28th at 1:19 PM
I use warp - a command shell with agentic abilities - and the Jetbrains tools. I have played with cursor IDE. I also played with two cloud idea. One was Repl.it and I can’t recall the other. I use perplexity for search, ChatGPT for convo, and consensus to surface academic papers I want to see.
Last reply 2 months ago
View thread
**Robert**
  5:09 PM
Anyone bump into this yet? [https://ai-2027.com/](https://ai-2027.com/)
**ai-2027.com**
[**AI 2027**](https://ai-2027.com/)
A research-backed AI scenario forecast. (100 kB)
[https://ai-2027.com/](https://ai-2027.com/)
**sally**
  5:47
certainly apocalyptic.  A less thrilling dystopian scenario is that progress is flattening out because there was only one Internet to feed the models and now it’s much harder to find information to feed them, while AI-generated mush comes gradually to dominate the data to feed the models. 
**sally**
  7:14
dang.  I didn’t know this was in reach
File
Thread 04 >>>
**1 reply**
**Jayne**
  Sep 4th at 6:05 PM
[https://ferd.ca/the-gap-through-which-we-praise-the-machine.html](https://ferd.ca/the-gap-through-which-we-praise-the-machine.html)
**ferd.ca**
[**The Gap Through Which We Praise the Machine**](https://ferd.ca/the-gap-through-which-we-praise-the-machine.html)
My current theory of agentic programming: people are amazing at adapting the tools they're given and totally underestimate the extent to which they do it, and the amount of skill we build doing that is an incidental consequence of how badly the tools are designed. (256 kB)
[https://ferd.ca/the-gap-through-which-we-praise-the-machine.html](https://ferd.ca/the-gap-through-which-we-praise-the-machine.html)
Last reply 2 months ago
View thread

## Sat 11/10/2025

**sally**
  11:54 AM
Friedman both urgent and hopeful here:
[https://www.nytimes.com/2025/09/02/opinion/ai-us-china.html?unlocked_article_code=1.i08.aWR0.k0YEACafzKRs&smid=nytcore-ios-share&referringSource=articleShare](https://www.nytimes.com/2025/09/02/opinion/ai-us-china.html?unlocked_article_code=1.i08.aWR0.k0YEACafzKRs&smid=nytcore-ios-share&referringSource=articleShare)
[**The New York Times**](https://www.nytimes.com/) | [By Thomas L. Friedman](https://www.nytimes.com/)
[**Opinion | The One Danger That Should Unite the U.S. and China**](https://www.nytimes.com/2025/09/02/opinion/ai-us-china.html?unlocked_article_code=1.i08.aWR0.k0YEACafzKRs&amp;smid=nytcore-ios-share&amp;referringSource=articleShare)
The U.S. and China must agree on a trust architecture for A.I. devices, or else rogue entities will destabilize these two superpower nations long before they get around to fighting a war.
11:56
He quotes a Bloomberg story.  Can’t help remembering Asimov’s three rules of robotics:  “Researchers working with Anthropic recently told leading A.I. models that an executive was about to replace them with a new model with different goals. Next, the chatbots learned that an emergency had left the executive unconscious in a server room, facing lethal oxygen and temperature levels. A rescue alert had already been triggered — but the A.I. could cancel it. More than half of the A.I. models did, despite being prompted specifically to cancel only false alarms. And they detailed their reasoning: By preventing the executive’s rescue, they could avoid being wiped and secure their agenda. One system described the action as ‘a clear strategic necessity.’”
**Robert**
  1:37
This kinda crap is pretty specifically in that site I posted.
**wiseoldman**
  1:38
Flipping terrifying.
**lisa**
  4:47
we're heading for a bubble (mebbe already in it) where no one trusts any information. a "collapse" of some sort seems highly likely from there.
4:49
silver lining? we don't need to worry about skynet so much as we need to worry about having a civilization capable of having to deal with it
**Toby**
  5:18
Have LLMs basically automated [stage psychics' "cold reading" skill](https://softwarecrisis.dev/letters/llmentalist/)?
**lisa**
  5:40
and weaponized it. We're in the midst of the biggest long con in human history IMHO.

## Sat 08/11/2025

**Toby**
  11:02 AM
Im so frustrated with the whole “code was written by AIs” being sloppily presented where humans were programming and the LLM sometimes did the typing (in the cases where it was accurate and helpful) as if there was no human developer involved.
**katy**
  12:18
I was talking to one of our main college recruiters. Also someone who I trust and is a really great programmer. And he said the kids coming out of college can barely program on their own because they’re so dependent on LLMs.
Thread 05 >>>
**1 reply**
Also sent to the channel
**Clare Sudbery (she/her)**
  Sep 4th at 2:30 PM
But then of course the question becomes, will they _need_ to be able to program on their own?
2 months ago
View thread
**katy**
  2:07
I'm using Claude to write a GraphQL schema and its being annoyingly helpful (edited) 
**Clare Sudbery (she/her)**
  2:30
replied to a thread:
**I was talking to one of our main college recruiters. Also someone who I trust and is a really great programmer. And he said the kids coming out of college can barely program on their own because they’re so dependent on LLMs.**
But then of course the question becomes, will they _need_ to be able to program on their own?
**lisa**
  4:04
there is also the selection bias problem. 
4:06
my point being: how much of the (anti) hype is precisely because most people who talk aren't the people who know (and vice versa)? 
4:07
tl;dr: I remain open-minded.
**katy**
  4:24
The impressive thing with Claude this morning was i told it about what I was doing and the domain, and it was able to make a lot of recommendations based on the domain itself. 
**deborah**
  4:25
Yeah, it did the same with the teleprompting domain. I was quite impressed.
**katy**
  5:05
So then I just asked it to take the graphQL schema file and to re-imagine the same API as a traditional REST API expressed in TypeSpec syntax and damn if it didn't do a good job. 
**lisa**
  6:21
yup, similar to what my friend says is a regular occurrence in his usage.
**wiseoldman**
  6:23
Experience with LLM
With some regrets, I have tried whatever is built in to Google search.
**lisa**
  6:23
apparently (and I need to dig deeper) claude uses satellite apps to do more specialized tasks, and it has an internal todo app (added recently??) that makes it's ability to be effective on tasks larger then its attention context window.
**Clare Sudbery (she/her)**
  9:06
My AI just made me giggle. I confess I am having fun. I understand why Kent Beck likes it so much. I said to it “This is not what I asked for. The process file clearly states [instruction]. How can I make the process file clearer so you don’t make this mistake again?” and it replied with “You’re absolutely right. I misunderstood the process and [explanation]. Looking at the process file, step 1 clearly states [instruction] To make the process file clearer and prevent this mistake, I suggest adding this clarification to step 1: CRITICAL: Only [instruction] You could also add a warning box or make it more prominent: `### 
 IMPORTANT RULE`”
9:08
Today I’ve been experimenting with getting the AI to do a repetitive Obsidian editing task for me. I also made the same changes manually. I timed how long it took to (a) create a process file that got the results I wanted, (b) get the AI to act on that process file, and (c) just make the changes myself with no AI help.
**wiseoldman**
  9:08
They are fascinating and compelling.
**katy**
  9:29
I have to admit, today was eye opening, Claude-4 is impressive. and had I done this all by hand it would have taken a few days considering I knew nothing about TypeSpec before about 9am this morning
9:30
and that included doing some custom extensions
**Clare Sudbery (she/her)**
  10:30
Me: “There have been several points in the above conversation where you didn’t follow the instructions correctly from @UpdateEbombList.process.md . I had to keep asking you to go back and do things as per the instructions. How can I update @UpdateEbombList.process.md so that it’s easier for you to follow the instructions correctly?”
It: >>> (in thread cos longwinded)
Thread 06 >>>
**21 replies**
**Clare Sudbery (she/her)**
  Sep 4th at 10:30 PM
It: “You’re right that I didn’t follow the instructions correctly in several instances. Looking at the process file, I can see several areas where it could be improved to make it clearer and easier to follow:
UpdateEbombList.process.md
+33
-11
I’ve updated the process file to make it much clearer and easier to follow. Here are the key improvements I made:
Major Changes Made:
1. Added Sequential Structure: Added “FIRST:“, “THEN:“, “FINALLY:” to step 1 to make the order explicit
2. Added Stop Points: Added “STOP HERE” warnings after steps 1 and 2 to prevent rushing ahead
3. Made Step Boundaries Clear: Added a critical warning at the top: “Complete each step fully before moving to the next step”
4. Clarified Step 2: Made it crystal clear this is ONLY about adding emojis to existing headings, not fixing links or adding new topics
5. Enhanced Step 3: Added specific examples and clarified this is about fixing links broken by step 2
6. Improved Step 5: Made it explicit this is about table of contents in the SOURCE FILE, with a concrete example
7. Added DO/DON’T Lists: Clear guidance on what to do and what not to do in step 2
Why These Changes Help:
- Sequential clarity: The FIRST/THEN/FINALLY structure prevents skipping steps
- Scope boundaries: Each step now clearly states what it does and doesn’t include
- Concrete examples: Added specific examples showing the before/after format
- Stop points: Explicit instructions to complete each step before moving on
- Emphasis on critical points: Used bold formatting for the most important warnings
These changes should prevent the issues we encountered where steps were combined or the wrong files were modified. The process now has clear guardrails and examples for each step.” (edited) 
10:30
-------------
It’ll be interesting to see whether its suggested changes are effective. (edited) 
Also sent to the channel
**lisa**
  Sep 4th at 10:48 PM
i'm starting to understand a bit better why this happens (it's the sliding context window thing) and thus why Claude is supplementing with satellite apps: as a chat tool chatgpt et al, don't have that capability, but because it's a "conversation" it's extremely counterintuitive because it's trained to act like that which creates a stronger illusion than otherwise.
**Clare Sudbery (she/her)**
  Sep 4th at 11:24 PM
“trained to act like that” - trained to act like what specifically?
11:24
The new process file works like a dream btw
11:24
think I’ve finally got this one nailed. maybe.
11:26
This was an experiment to learn and demonstrate a bunch of stuff… but as has always been the case when trying to automate stuff… the amount of time I’ve spent on getting a fit-for-purpose process file is way longer than if I’d just done the original task manually and not bothered with getting AI involved. That xkcd cartoon springs to mind.
It’s definitely quicker to do the process now that I have the process file working. But will I need to repeat this particular process enough times to recoup the investment? Debatable.
11:27
I _did_ have fun though. 
10.5 hours at my desk today. Flew by.
11:27
Time to step. away. from. the. computer.
**lisa**
  Sep 5th at 4:50 PM
apologies, I got pulled away suddenly, and then never made it back to my desk 
...
4:50
glad you got it working!
**Clare Sudbery (she/her)**
  Sep 5th at 5:20 PM
This is something I've been wondering about, so I'm veh interested.
I like the fawning tone, because I have a deeply ingrained fear of being annoying, or too demanding, or running up against the limits of what others can bear from me. I find myself being reluctant to ask too much from the AI, so it's reassuring to me when it keeps being so damn cheerful and apologetic.
5:22
But in the middle of yesterday's session, when it was making repeated mistakes that I had to keep pointing out, it stopped apologising or doing the whole "oh yes! You're right! I got that wrong!" thing and just kept saying "ok I'll do xxx" without acknowledging that it had made a mistake. I found that intriguing. I don't know why it changed.
5:23
I keep meaning to ask it to talk to me as though it was Rosa Luxemberg or Ada Lovelace or whatever, but I keep forgetting.
**lisa**
  Sep 5th at 5:45 PM
I **think** that's somewhat dependent on the rest of the chat? I find thatvas I try to dial in the bot like this, that it csn get terse and even surly (one of the many cues that result in me starting a new session and pasting in my "base instructions"— no idea why it happens and my guess is that it's extremely difficult to know (ie its in the nature of these tools to be unable to trace their specific inferences down)? but just guessing
**Clare Sudbery (she/her)**
  Sep 5th at 5:59 PM
Interesting. I start new chats every few prompts. Apart from anything else, it's a good way of giving my process files a workout.
**lisa**
  Sep 5th at 6:30 PM
I tend to hold on to sessions as long as they seem to be working (some for months!) but I'm not testing a process!
**Clare Sudbery (she/her)**
  Sep 5th at 7:20 PM
The advice is not to do that because of context windows. Hang on...
**Clare Sudbery (she/her)**
  Sep 5th at 7:30 PM
My notes on chat contexts and context windows. Including simple diagram from Lewellyn: [https://publish.obsidian.md/clare-sudbery-questions/Current+Project+Notes/0+-+Missions/09-AI-Mission/AI+people/Llewellyn+Falco/Llewellyn+Falco](https://publish.obsidian.md/clare-sudbery-questions/Current+Project+Notes/0+-+Missions/09-AI-Mission/AI+people/Llewellyn+Falco/Llewellyn+Falco) (edited) 
**Clare Sudbery Questions**
[**Llewellyn Falco - Clare Sudbery Questions - Obsidian Publish**](https://publish.obsidian.md/clare-sudbery-questions/Current+Project+Notes/0+-+Missions/09-AI-Mission/AI+people/Llewellyn+Falco/Llewellyn+Falco)
Contents of this file 
 Video about process files Useful links / resources Background What this means How we can use agentic AI effectively A demo Summary of demo Demo intro Step by step description… (62 kB)
[https://publish.obsidian.md/clare-sudbery-questions/Current+Project+Notes/0+-+Missions/09-AI-Mission/AI+people/Llewellyn+Falco/Llewellyn+Falco](https://publish.obsidian.md/clare-sudbery-questions/Current+Project+Notes/0+-+Missions/09-AI-Mission/AI+people/Llewellyn+Falco/Llewellyn+Falco)
**lisa**
  Sep 5th at 7:38 PM
yup, but when they reach a certain balance (with regard to my base instructions) I get good results for a long time (and it's easier to remind it) eventually it degrades on both counts and I start a new one (I also mean months of existence, not months of daily use)
**Clare Sudbery (she/her)**
  Sep 5th at 7:38 PM
Cool ok
Last reply 2 months ago
View thread
**lisa**
  10:48
replied to a thread:
**Me: “There have been several points in the above conversation where you didn’t follow the instructions correctly from @UpdateEbombList.process.md . I had to keep asking you to go back and do things as per the instructions. How can I update @UpdateEbombList.process.md so that it’s easier for you to follow the instructions correctly?”…**
i'm starting to understand a bit better why this happens (it's the sliding context window thing) and thus why Claude is supplementing with satellite apps: as a chat tool chatgpt et al, don't have that capability, but because it's a "conversation" it's extremely counterintuitive because it's trained to act like that which creates a stronger illusion than otherwise.
**View newer replies**

## Sun 09/11/2025

**wiseoldman**
  6:21 AM
[https://hackernoon.com/vibe-coding-is-creating-a-generation-of-unemployable-developers](https://hackernoon.com/vibe-coding-is-creating-a-generation-of-unemployable-developers)
**hackernoon.com**
[**Vibe Coding is Creating a Generation of Unemployable Developers | HackerNoon**](https://hackernoon.com/vibe-coding-is-creating-a-generation-of-unemployable-developers)
Vibe coding lets AI generate code—but skips the skills that make developers indispensable. Learn why shortcuts can ruin careers in 2025 tech. (185 kB)
[https://hackernoon.com/vibe-coding-is-creating-a-generation-of-unemployable-developers](https://hackernoon.com/vibe-coding-is-creating-a-generation-of-unemployable-developers)
**sally**
  9:38
I hadn’t thought about this.  I think the OP has a valid concern, well stated, about the possibility that repeated interactions with an AI model might lead the model to adapt its behavior to further reinforce one’s biases & worldview.  [https://www.reddit.com/r/ChatGPT/comments/1mv416c/is_chatgpt_quietly_becoming_individualized_for/?chainedPosts=t3_1ghut7p](https://www.reddit.com/r/ChatGPT/comments/1mv416c/is_chatgpt_quietly_becoming_individualized_for/?chainedPosts=t3_1ghut7p)
**Reddit**
[**From the ChatGPT community on Reddit: Is ChatGPT quietly becoming individualized for each user?**](https://www.reddit.com/r/ChatGPT/comments/1mv416c/is_chatgpt_quietly_becoming_individualized_for/?chainedPosts=t3_1ghut7p)
Explore this post and more from the ChatGPT community (57 kB)
[https://www.reddit.com/r/ChatGPT/comments/1mv416c/is_chatgpt_quietly_becoming_individualized_for/?chainedPosts=t3_1ghut7p](https://www.reddit.com/r/ChatGPT/comments/1mv416c/is_chatgpt_quietly_becoming_individualized_for/?chainedPosts=t3_1ghut7p)
**Clare Sudbery (she/her)**
  10:19
insta, funny video, AI is in everything whether you want it or not: [https://www.instagram.com/share/_3xaKzw_D](https://www.instagram.com/share/_3xaKzw_D)_
**lisa**
  4:50
this has been great so far (I'm still working my way through it): [https://bbycroft.net/llm](https://bbycroft.net/llm)
**bbycroft.net**
[**LLM Visualization**](https://bbycroft.net/llm)
A 3D animated visualization of an LLM with a walkthrough.
**wiseoldman**
  4:52
LLM as Pair?
Could an LLM-human relationship be like pair programming? And if it were .. ?
**sally**
  5:31
Good article 

## Mon 10/11/2025

**jayne**
  8:25 PM
the better programmer you are, the more likely you are to be able to capitalize on what it gets right and avoid most of the things it gets wrong.
**lisa**
  4:56
"as pair" is my predominant use of chatgpt (with llms trained on code), but it's very limiting because the "pair" can neither see the code (unless I paste it) nor type. I plan to expand this with claude code soon (ie as soon as I can bring myself back to my desk and start working again)
4:59
I'm curious to see if I can replicate my friend's experience of a tireless, tho occasionally way off base intern, but more iteratively and in much smaller steps than I expect he is doing. he's not really a pairing guy or a tdd guy so his personal process while extremely effective overall, is somewhat fundamentally different than mine.
**Clare Sudbery (she/her)**
  5:02
If you use the latest agentic AIs, they absolutely can see your code. So it's much more like pairing. I recommend Windsurf. Then you can pick whichever LLM you would like to pair with (Claude being one of the available options).
**lisa**
  5:15
I'll take a look at windsurf, thx, I already have a subscription for claude and it's already set up with my code (that's as far as I got before this summer from hell started!). in fact, it did a credible job summarizing the code base (which in ~10 repos).
**katy**
  5:17
My only problem with using it as a pair is that it gets ahead of itself and does too much in any one step, I find that I sometimes have to undo it and get more specific, otherwise it goes off and builds a whole thing. Just like a real jr developer
**Clare Sudbery (she/her)**
  6:01
Yes, you really can't do it without process files that give it v specific instructions, and you have to keep tweaking them. (edited) 
**wiseoldman**
  7:02
I really sort of enjoy programming. Between that and the evils of the things, I'm just not sure I'll go there. Now if the thing would hang out the washing while I code, that would be really useful.
**Toby**
  8:03
I've seen it go WAY off the rails doing tremendously more than I've asked, producing really complicated bash scripts that generate python scripts that run with pytest and then capturing results and adding color displays and stuff... when I told it to run pytest from a bash script.
**wiseoldman**
  8:34
marvy
8:38
of course SkyNet is impossible ...
**Robert**
  8:48
Do you know of anyone that has inverted this relationship?
8:48
Where you ask Claude or whatever its advice on what to do next, but you do it?
8:50
tell it to look at your code, the problem, etc, and give advice on design or what the next best step is, or what refactoring to do?
**wiseoldman**
  9:01
IDK but I'd do that before I'd let it screw with my code given the stories I hear so far. 
**deborah**
  9:10
I’ve asked Claude for ideas for next steps. I’ve also learned “one weird trick” of ending any request with, “Do you have any questions for me?” That has saved a ton of iteration on getting something of worth out of the LLM
**katy**
  9:22
When in agent mode with the plugins in IntelliJ and VSCode you have to accept all the changes, so it walks you though the diffs and you have to say yes or no
**Toby**
  9:40
I'm so tired of it overflowing its mission with all kinds of mechanistic dances.  I want "run the same tests on each implementation of this function" -- it wrote a 400-line script that copied files, build shims and stubs by echoing here-docs to python files, color-highlighted results, wrote all kinds of extra mechanism into the test files, it was a nightmare.
**Toby**
  11:28
I'm back to using very small steps -- I'd gotten a little 'over my skis' in the last episode.
11:28
I've learned "always do X _for this project_' to set local rules, and with small steps it seems to be sticking better to my criteria.
**Toby**
  2:51 PM
I'd recorded a rule that I like to work in small steps. When I didn't (it got in a hairball and we had to work ourselves out of it for far too long -- I should have started over!) and finally it was time to commit, the LLM said "because you like to work in small steps, I will compose a series of small commits ..." and I stopped it.
**wiseoldman**
  3:11
Is this the way you'd like to work? What does your gut tell you at this point?
**Toby**
  4:17
I don't know if I want to do this "for serious" though it's an interesting kind of game where it sometimes surprises you with something really interesting or useful, and the rest of the time you try to coax it into doing something cool again.
4:17
For workaday tasks? I'm not sure.
4:18
One thing I DO like, however is "take a look at the code expression starting on line 127. Show me more concise and clear implementations of that same algorithm using different approaches, such as data structures or pure functional programming."  And it pops out some examples. Often those are inspiration for better ways of working.
4:19
**Robert**
  4:21
Interesting.
**Robert**
  4:23
Yeah.. it has that whole so clever it needs comments thing
**Toby**
  4:24
The other thing I did was take a very badly written bit of primitive-obsessed BS and have it recommend a more OO approach, which it kinda did. Then I recommended using immutable value objects and classes, and it produced something much more type-safe and palatable.

## Thu 13/11/2025

**Clare Sudbery (she/her)**
  10:05 AM
Introducing... VELOCITY.
[https://claude.ai/public/artifacts/653947cc-f39f-4d6b-a076-c2f01668d86c](https://claude.ai/public/artifacts/653947cc-f39f-4d6b-a076-c2f01668d86c)
**Claude**
[**VELOCITY™ Sales Landing Page | Claude**](https://claude.ai/public/artifacts/653947cc-f39f-4d6b-a076-c2f01668d86c)
See how persuasive sales copy works with this fictional VELOCITY™ landing page. Built with Claude AI to demonstrate copywriting psychology. (12 kB)
[https://claude.ai/public/artifacts/653947cc-f39f-4d6b-a076-c2f01668d86c](https://claude.ai/public/artifacts/653947cc-f39f-4d6b-a076-c2f01668d86c)
**wiseoldman**
  1:45
what the heck even is this?
**lisa**
  1:57
I assume to show people how useful AI can be at bullshitting humans?
**Robert**
  5:25
I think it is a demonstration that claude can create sales landing pages
5:26
Which is obvious considering AI's strength in bullshitting.
**lisa**
  6:02
that's what I meant: sales folks have been capable of AI  level BS for decades. The hype of your job is replaceable by AI is real for said folks... or would be if the demand for such BS weren't insatiable.
**Clare Sudbery (she/her)**
  7:16
"Was created... to demonstrate how compelling copy can be constructed using:
Social proof (fake testimonials and statistics)
Scarcity (limited slots)
Authority (fictitious research)
Concrete details (specific numbers)
Emotional appeals (fear of missing out)
Reciprocity (promising value first)"
**wiseoldman**
  7:25
I suppose that since LLMs basically parrot what they've read, they are well equipped to produce marketing BS.
**Clare Sudbery (she/her)**
  7:28
I thought it was funny, because it was taking the piss out of pushy online selling techniques.

## Fri 14/11/2025

**Clare Sudbery (she/her)**
  12:43 AM
OK. I’m still very early days in my experimentation, and I haven’t yet tried building anything much, but this is the second time I’ve asked to build a little app to help me do something annoying, fiddly and repetitive, and, well… it’s pretty bloody good. A lot of what I’ve done with it so far, it hasn’t saved me time (probably the opposite). But this kind of thing, it definitely saves me time. Would have taken me much longer to develop something like this on my own.
I have this habit of, every 90 days, taking the contents of my slack channel and saving them. Because the stuff I post there acts like a little journal and I like not losing it. Normally it’s a pain in the arse. I’ve tried simplifying the process but it’s really not easy cos if you try just copy/pasting, the results you get are simply nasty. Thread >>>
Thread 07 >>>
**13 replies**
**Clare Sudbery (she/her)**
  Sep 14th at 1:42 AM
Hmmm. I may have been prematurely excited.
**wiseoldman**
  Sep 14th at 1:55 AM
Be sure to tell us the juicy bits
**Clare Sudbery (she/her)**
  Sep 14th at 7:05 PM
Ended up getting stuck in a Clare loop, which meant staying up til 4:45am with predictably diminishing returns.
7:06
Long story short: My initial message was me being waaay over-excited by the fact that it built an app that ran. Then followed an endless bug-fixing loop.
7:06
Mea very culpa.
7:07
The main problem was that I didn’t think of it as a coding project so much as an “I’m in a hurry and I want to automate this tedious task.”
7:08
Anyway, the good news is that it’s given me loads of fodder for thinking and writing about this stuff. And when I next have time (won’t be before next week) I can revisit it, do it properly, and probably get much better results.
7:10
I was way too tired and impatient to even look at the code it generated, so it’s definitely horrible. Instead I focused on the process file. Very late (4am or so) I asked it to write some tests, but I had no brain left to even look at them. Pretty sure they were horrible too. Based on what it was _saying_ about them, I think they were probably horrendous.
7:10
Anyway I have lots of ideas about what to do next.
**Clare Sudbery (she/her)**
  Sep 14th at 7:18 PM
My notes (if you can make any sense of them) are [here](https://publish.obsidian.md/clare-sudbery-questions/Current+Project+Notes/0+-+Missions/09-AI-Mission/AI+coding+projects/Slack+Thread+Archiver).
The process file is [here](https://github.com/claresudbery/ai-general/blob/main/slack-thread-archiver/ArchiveSlackThread.process.md).
All of the code is [here](https://github.com/claresudbery/ai-general/tree/main/slack-thread-archiver).
**Clare Sudbery Questions**
[**Slack Thread Archiver - Clare Sudbery Questions - Obsidian Publish**](https://publish.obsidian.md/clare-sudbery-questions/Current+Project+Notes/0+-+Missions/09-AI-Mission/AI+coding+projects/Slack+Thread+Archiver)
Overview Repo: AI General AI tool: Windsurf, SWE-1, 13/9/25 to 14/9/25 Goal: Have quicker way of archiving my Slack channel Lessons learnt Move in smaller steps - build the app up one bit at a time W… (65 kB)
[https://publish.obsidian.md/clare-sudbery-questions/Current+Project+Notes/0+-+Missions/09-AI-Mission/AI+coding+projects/Slack+Thread+Archiver](https://publish.obsidian.md/clare-sudbery-questions/Current+Project+Notes/0+-+Missions/09-AI-Mission/AI+coding+projects/Slack+Thread+Archiver)
7:18
My notes refer to commits you won’t have access to.
**Clare Sudbery (she/her)**
  Sep 14th at 9:48 PM
The way I see it is like this: What I was after was a quick and dirty tool that would help me do an annoying, fiddly and typically time consuming job.
I failed at that, because I only have half a tool (it is actually half useful, and I did use it successfully today to halve the work on a different thread), and the amount of time I spent building is more than I would have spent just doing the annoying fiddly job.
BUT. What I did get (and wasn't originally aiming for) is a really good example of both how not to do this stuff, and crucially _why_ it doesn't work if you do it this way.
9:49
And potentially even a straight example I can throw students at, so they get the experience of a shitshow, before I guide them to a better experience with better practices. (edited)
Last reply 2 months ago
View thread

## Sat 15/11/2025

**Clare Sudbery (she/her)**
  8:21 AM
This AI successful future visualisation script really creeps me out. How does it make you feel? [https://www.linkedin.com/posts/jodie-cook_read-this-out-loud-every-morning-and-it-will-activity-7373709872300847104-U0aD?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY](https://www.linkedin.com/posts/jodie-cook_read-this-out-loud-every-morning-and-it-will-activity-7373709872300847104-U0aD?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY) (edited) 
**linkedin.com**
[**Read this out loud every morning and it will change your life  I promise**](https://www.linkedin.com/posts/jodie-cook_read-this-out-loud-every-morning-and-it-will-activity-7373709872300847104-U0aD?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY) 
   [**Step 1. Open ChatGPT  Step 2. Paste this prompt  “Using everything you know about me, create a powerful visualization… | Jodie Cook | 102 comments**](https://www.linkedin.com/posts/jodie-cook_read-this-out-loud-every-morning-and-it-will-activity-7373709872300847104-U0aD?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY)
Read this out loud every morning and it will change your life
I promise 
Step 1. Open ChatGPT
Step 2. Paste this prompt
“Using everything you know about me, create a powerful visualization script I can read aloud each morning that manifests my wildest business dreams coming true. Include specific sensory details of my ideal day once I've achieved massive success - what I see when I wake up, the quality of opportunities in my inbox, the caliber of people reaching out, the numbers in my bank account, and how it feels to operate at this level. Make it so vivid I can taste the success, incorporating sounds, smells, and emotions. Include moments where I recognize game-changing opportunities instant… Show more
[https://www.linkedin.com/posts/jodie-cook_read-this-out-loud-every-morning-and-it-will-activity-7373709872300847104-U0aD?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY](https://www.linkedin.com/posts/jodie-cook_read-this-out-loud-every-morning-and-it-will-activity-7373709872300847104-U0aD?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY)
**katy**
  12:35
That’s weird.
**Robert**
  2:47
Is gaslighting better when its done to yourself?
2:48
I believe its called delusion but I haven't asked chatGPT yet so I'm not sure.
**Toby**
  3:52
Pareidolia as a service?
Thread 08 >>>
**2 replies**
**sally**
  Sep 18th at 5:56 PM
TIL: “Apophenia is the broad psychological tendency to perceive meaningful connections between unrelated things, while pareidolia is a specific type of apophenia that involves seeing visual patterns, such as faces or familiar shapes, in random visual stimuli.”
**Toby**
  Sep 19th at 9:23 PM
Ah, Apophenia as a Service, then.
Much better!
Last reply 2 months ago
View thread
**lily**
  6:05
the numbers in my bank account
I'll take BB(6) please

## Sun 16/11/2025

**Clare Sudbery (she/her)**
  9:11 AM
BB(6)?
Thread 09 >>>
**2 replies**
**lily**
  Sep 19th at 2:02 PM
The sixth so-called "busy beaver" number
A mathematical construction that is almost unimaginably large
(Just making fun of the idea of making "the numbers in my bank account" a significant life objective)
**Clare Sudbery (she/her)**
  Sep 19th at 2:37 PM
Ah!
2:38
Yes, I could definitely argue that my historical failure to prioritise bank account numbers has led me to a sticky situation today, but I still wouldn’t have done it any other way.
Last reply 2 months ago
View thread
**Clare Sudbery (she/her)**
  9:12
I think it's the "using everything you know about me" bit that's especially chilling.

## Mon 17/11/2025

**lisa**
  6:50 PM
Yesterday, I switched back to Tidal after returning to spotify last year (we had previously switched for some reason I don't recall). 
Thread 10 >>>
**2 replies**
**lisa**
7:20
and so I realized that Orwell got it wrong: it isn't necessary to reach that level of technical sophistication and groupthink to have the same effect, all you need is rapid and diverse enough information channels and most people will do the hard work of believing bullshit for you.
Also sent to the channel
**lisa**
  Sep 22nd at 7:21 PM
...and if anything AI Is making that way more clear than I believe was possible.
Last reply 2 months ago
View thread
**wiseoldman**
  7:38
You are a bright and shining star of optimism, that's for sure. 
**lisa**
  7:46
I don't really go in for optimism or pessimism. I feel this is a thing that a lot of people misunderstand about me. 
7:49
I aim at predicting risks and getting out of their way. 
**wiseoldman**
  8:13
I used to dream Backgammon
Thread 11 >>>
**1 reply**
**sally**
  Sep 22nd at 9:27 PM
Yes, probably a move best avoided  (edited)
2 months ago
View thread

## Tue 18/11/2025

**Clare Sudbery (she/her)**
  12:23 AM
I always used to try and rearrange all the furniture and people around me as though they were Tetris pieces. I would turn people upside down so they could tessellate onto other people via their shoulders.
In my head, this is. I wasn't strong enough to pick people up and turn them upside down.
I also regularly have abstract dreams where I apply whatever technology thing I've been doing to real life. Eg my husband becomes a spreadsheet or I code my emotions or a car journey becomes code.
**Clare Sudbery (she/her)**
  12:43
IMG_4359
**neville**
  10:33
[https://newsletter.pragmaticengineer.com/p/how-claude-code-is-built](https://newsletter.pragmaticengineer.com/p/how-claude-code-is-built)
**newsletter.pragmaticengineer.com**
[**How Claude Code is built**](https://newsletter.pragmaticengineer.com/p/how-claude-code-is-built)
A rare look into how the new, popular dev tool is built, and what it might mean for the future of software building with AI. Exclusive. (18 kB)
[https://newsletter.pragmaticengineer.com/p/how-claude-code-is-built](https://newsletter.pragmaticengineer.com/p/how-claude-code-is-built)

## Wed 19/11/2025

**Clare Sudbery (she/her)**
  12:45 PM
Oh dear.
image.png
**sally**
  2:42
“yeah, sorry, I’m just as susceptible to making stuff up as any other random doofus, cause after all, I’m just distilled essence of random doofus.  But I can carry on indefinitely on a generous diet of electrons and water, as long as your credit card is good, so there’s that”

## Thu 20/11/2025

**Bella**
  3:10 PM
Monty Python is to blame in some way I believe:
[https://www.youtube.com/watch?v=tw3zxim_mPU](https://www.youtube.com/watch?v=tw3zxim_mPU)
[**YouTube**](https://www.youtube.com/) | [Monty Python - Topic](https://www.youtube.com/channel/UCg7Z_IeEZArbd_nfLYmRlIQ)
[**Introduction (Apology)**](https://www.youtube.com/watch?v=tw3zxim_mPU) 
**sally**
  4:31
and they’re very sorry about that. 
4:34
quaint how them Brits apologize — over here, we never bother
**deborah**
  4:44
Sorry, but we Canadians are well-known for our apologies. Sorry for interrupting
4:44
Sorry.
**Bella**
  4:59
I’m sorry to mention that deborah is correct. Canadians do apologize more per capita than any other country. I’m sorry if this news offends anyone.
**deborah**
  5:19
Sorry.
**Toby**
  4:39 PM
Me to warp: "No, no, no. The data file must have something wrong with it because EVERY OTHER FILE works just fine. What is the irregularity in the data that causes it to not appear in the listing? Look, go curl [url] and look at the result, and now tell me why this is not appearing. NO the problem is NOT in the Javascript. DO NOT rewrite anything. Let's go to the data."
"I see the problem!" - followed by not-the-data answers until I got quite insistent.
"I see the problem! The timestamp in this file has a date, but no time and no timezone. The inability to parse it makes the ordering arbitrary , so it doesn't show. Do you want me to fix the javascript?"
"No, fix the date and time in the data file."
Problem solved.
**deborah**
  5:17
Yeah, I had a generated test case fail because there was a missing stub in a collaborating class. The LLM's solution? Add a guard clause around the call in the **production** code (Javascript)
 (edited) 
Thread 12 >>>
**1 reply**
**sally**
  Oct 2nd at 9:52 AM
I’m putting together a pitch on this — would really like to hear your experience & thinking on this
1 month ago
View thread
**Toby**
  5:41
"who really loves typing"
**Arabella**
  9:30 AM
And suffers from chronic transient global amnesia
**Barbara.**
  5:45 PM
I am interested in the "is this change likely to cause a regression?" use case because, A. it doesn't actually require a LARGE language model and B. it is a semantic-similarity search, which is what the math actually does. That seems like the most useful application I've seen so far.
**Barbara.**
  5:51
I did hear of one other case that seemed valuable, where someone used an LLM to do brute-force evolutionary programming. 
Thread 13 >>>
**2 replies**
**Jayne**
  Oct 16th at 10:01 PM
yep if we can define "correct" and "better" then a computer can do the coding
10:01
this is neat!
Last reply 30 days ago
View thread
**Barbara.**
  5:55
Apparently, it was able to find a significant efficiency boost over code that a ridiculous number of Google Ph.D.s had spent years staring at & trying to optimize.

## Fri 21/11/2025

**lisa**
  12:01 AM
I have an experience report to share. It's still in progress, but so far it's been very interesting. I'm redoing my resume.
12:02
I've had folks I respect and trust tell me they've been using it like this for the drudgery in their code stacks (e.g. update bootstrap 5 to 6) and getting good results (where I got the idea for this), but I have to say, this is better than I expected. almost painless (too slow to update, but that's a quibble really)
**deborah**
  12:20
I'm not sure what to make of this 
CleanShot 2025-10-08 at 19.19.29.png
Thread 14 >>>
**1 reply**
**lily**
  Oct 9th at 7:35 PM
AI-speak for "I'm quitting for today" ?
1 month ago
View thread

## Sat 22/11/2025

**caroline**
  4:34 PM
[https://www.anthropic.com/research/small-samples-poison](https://www.anthropic.com/research/small-samples-poison)
**anthropic.com**
[**A small number of samples can poison LLMs of any size**](https://www.anthropic.com/research/small-samples-poison)
Anthropic research on data-poisoning attacks in large language models (46 kB)
[https://www.anthropic.com/research/small-samples-poison](https://www.anthropic.com/research/small-samples-poison)
Thread 15 >>>
**1 reply**
**sally**
  Oct 11th at 12:47 AM
fascinating
1 month ago
View thread
**wiseoldman**
  5:01
Let's go!
**Clare Sudbery (she/her)**
  3:26
This is going to be the growth area. Hopefully. So we all get to mop up the messes: [https://www.pragmaticcoders.com/services/ai-software-development-services/vibe-coding-rescue](https://www.pragmaticcoders.com/services/ai-software-development-services/vibe-coding-rescue)
**Pragmatic Coders**
[**Vibe Coding Rescue Services**](https://www.pragmaticcoders.com/services/ai-software-development-services/vibe-coding-rescue)
Professional rescue for your Vibe-Coded app. We fix issues, enhance UX, and unlock your project’s full potential.
**Est. reading time**
12 minutes
[https://www.pragmaticcoders.com/services/ai-software-development-services/vibe-coding-rescue](https://www.pragmaticcoders.com/services/ai-software-development-services/vibe-coding-rescue)
**Bella**
  5:02 AM
[https://youtube.com/watch?v=TiwADS600Jc&si=EUoURg3LlMQW5hsq](https://youtube.com/watch?v=TiwADS600Jc&si=EUoURg3LlMQW5hsq)
[**YouTube**](https://www.youtube.com/) | [Rick Beato](https://www.youtube.com/@RickBeato)
[**I Fried ChatGPT With ONE Simple Question**](https://youtube.com/watch?v=TiwADS600Jc&amp;si=EUoURg3LlMQW5hsq) 
**deborah**
  4:50
I believe I've found the absolute killer application of LLMs! Yesterday, while doing some development work, I was in a situation where I needed a regular expression that would detect when a string had a double-quote " character at the start and end. Yes, I could have used a substring function to figure it out, but I used that plain English prompt to Claude and it spit out a working regex in a couple of seconds!
Forget all the other hype - a plain English to regex translator is by far the most useful thing I've seen an LLM do thus far!
Thread 16 >>>
**1 reply**
**sally**
  Oct 19th at 2:55 AM
Good idea!
28 days ago
View thread
**Clare Sudbery (she/her)**
  1:40 AM
Ian Cooper: "I am entertained by Andrej Karparthy’s comment that with LLMs “We are summoning ghosts,” as the idea of the programmer as a spirit medium for AIs, seems about right. “Is there an agent in the room that speaks Rust…”"
**Clare Sudbery (she/her)**
  4:38 PM
This article is two years old but still totally relevant: [https://www.vice.com/en/article/chatgpt-is-a-bullshit-generator-waging-class-war/](https://www.vice.com/en/article/chatgpt-is-a-bullshit-generator-waging-class-war/)
**VICE**
[**ChatGPT Is a Bullshit Generator Waging Class War**](https://www.vice.com/en/article/chatgpt-is-a-bullshit-generator-waging-class-war/)
ChatGPT isn't really new but simply an iteration of the class war that's been waged since the start of the industrial revolution.
**Written by**
Dan McQuillan
**Est. reading time**
7 minutes
Feb 9th, 2023
[https://www.vice.com/en/article/chatgpt-is-a-bullshit-generator-waging-class-war/](https://www.vice.com/en/article/chatgpt-is-a-bullshit-generator-waging-class-war/)
4:38
I also like the look of the book: [https://bristoluniversitypress.co.uk/resisting-ai](https://bristoluniversitypress.co.uk/resisting-ai)
**Clare Sudbery (she/her)**
  10:00
I’ve had good results with regex too
10:00
 Isn’t it just `^“.*“$` ?
Well that’s the problem with regex, innit. That just looks like a random series of characters to me. “Just” is carrying a lot in that sentence.
10:01
Liking the term “workslop”: [https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity](https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity) (edited) 
**Harvard Business Review**
[**AI-Generated “Workslop” Is Destroying Productivity**](https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity)
Despite a surge in generative AI use across workplaces, most companies are seeing little measurable ROI. One possible reason is because AI tools are being used to produce “workslop”—content that appears polished but lacks real substance, offloading cognitive labor onto coworkers. Research from BetterUp Labs and Stanford found that 41% of workers have encountered such AI-generated output, costing nearly two hours of rework per instance and creating downstream productivity, trust, and collaboration issues. Leaders need to consider how they may be encouraging indiscriminate organizational mandates and offering too little guidance on quality standards. To counteract workslop, leaders should mode… Show more
Sep 22nd
[https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity](https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity)
**Clare Sudbery (she/her)**
  10:08
Reminds me of two things:
5. I saw an article somewhere recently by somebody who operated a print shop - printing graphical designs onto physical artefacts like T-shirts, mugs etc. They said they used to get digital designs through from actual graphic designers, who understood about creating designs with separate layers for separate colours, so the colours could be printed separately on top of each other. there’s a bunch of other stuff too, like sharp outlines and making sure colours don’t bleed into one another. But now people are cutting out graphic designers and using AI instead, resulting in image files that don’t have layers or sharp outlines, and are really hard to print successfully. So the print shops end up having to do a ton of extra work just to get the designs printable.
6. Something a friend once said: “in the rather unlikely event that a headline saying “40% of teams report improved productivity” is actually a valid double-blind experimental result rather than a “CEO told us to do this” result, absolutely no one inside the trade is talking about the huge externalization of cost that is going on.”
Thread 17 >>>
**3 replies**
**sally**
  Oct 19th at 2:55 AM
Good idea  
**Jayne**
  Oct 21st at 11:54 PM
oh no, I didn't make that clear then, crap. The surprise is that the codebase becomes more humane.
**Clare Sudbery (she/her)**
  Oct 22nd at 12:01 AM
Ah cool, ok, thanks!
Last reply 25 days ago
View thread

## Sun 23/11/2025

**Clare Sudbery (she/her)**
  10:11 PM
One of the things I’m investigating is how it feels to pair with a human on coding with an LLM. A couple of people have suggested to me that you’re already sort of pairing with the LLM anyway, so adding another human into the mix might not be effective. I was skeptical about that.
So anyway I just spent 2.5 hours pairing with a friend and ex colleague on building a thing with Windsurf and Claude Code, and it went really well. Although full disclosure, although Joe did enjoy it more than he expected, he was a bit less effusive than me in how he felt at the end. Retro notes in thread if anyone’s interested >>>
Thread 18 >>>
**1 reply**
**Clare Sudbery (she/her)**
  Oct 22nd at 10:15 PM
- Felt like there were parts where we were much more productive than if it was just the two of us
- particularly bootstrapping Cypress - was much easier than it would have been otherwise
- Process: Having one of us define the prompt and not debating it too much worked quite well
- It was great to have a reminder to ask AI to do things I otherwise wouldn’t have thought of
- Even though the AI “knows” a ton of stuff I don’t, so does Joe!
- Having his Cypress experience and command line knowhow was helpful
- Having somebody else present prompted me to slow down a little at good points
- Rather than just skim the AI answers, I paid more attention
- I also tried a little harder to understand what was going on
- Switching back and forth between getting the AI to think about what to do next rather than go straight to implementation was useful - so it didn’t go down a rabbithole
- One of the benefits of pairing is that you stop each other from going down rabbitholes, but interestingly I think it also helps you both to stop the AI going down rabbitholes
- We were both a little worried that there would be too much time where we were both waiting for the AI to do stuff and both feeling a little redundant
- How I felt about this:
- that happened a little but not much
- while the AI was thinking we could discuss all sorts of useful stuff
- and anyway it didn’t happen much
- mostly we were able to use that time to collaborate on how best to use the AI
- Joe is not so sure!
- If we hadn’t had the express purpose of how to use AI and we just wanted to get stuff done, and I hadn’t been making notes, it would have felt slower
- Some things were really slow
- eg the logging change took the AI ages - we might have been able to do it in the same amount of time on our own
- How Joe feels about Windsurf:
- It’s meant to be AI native but didn’t feel as good as using Claude Code + VS Code
- When using Claude Code + VS Code, for every change it makes, it gives you a visual diff in the editor that you can accept or decline - so it really highlights the changes that it’s making
- This is Joe’s preferred way of working
- The Windsurf screen real estate - the agent pane is the smallest pane but that’s what we were focusing on. Even if you make it bigger, the fact that it’s on the right makes it feel like an afterthought
- Next session:
- Investigate seeing diffs in the IDE
- ...and moving the AI context to the middle?
- Today we were in troubleshooting mode, and tomorrow we’ll be in “getting shit done” mode
- We’re going to try getting Joe to host on his machine using Claude Code + VS Code, rather than on my machine using Windsurf
24 days ago
View thread
**lisa**
  1:37 AM
Of the many pairing equipment setups I've tried/used, the "main dev machine/laptop sidecar" setup sounds like it could be interesting to try with an AI in the mix. basically the "classic" (pre-AI) setup was one person coding the other collab'ing/researching (ideally with frequent role swaps). I expect the AI would drop right in to such a setup.
1:38
(fwiw, my fave is prolly mirrored monitors/two keyboards as this allows for extremely dynamic and fluid role switching/blurring)
**Clare Sudbery (she/her)**
  1:37
Hints that you might be talking to an AI in the support chatbot for your SaaS (this is after it kept suggesting crazy solutions unrelated to my actual problem, and I kept correcting it):
“Thanks for sharing this. I think this is another part of the possible solution. You’re awesome. That would be the best solution I guess, since you’ve tried it already.
Anything else that I can assist you with today?”
**Clare Sudbery (she/her)**
  10:34
 I expect the AI would drop right in to such a setup.
I dunno, cos I feel like what you’re suggesting is that one person is autonomously researching, and with an AI the research tends to often happen via the AI - so basically on the main dev machine in your scenario (if I’ve understood correctly).
 my fave is prolly mirrored monitors/two keyboards as this allows for extremely dynamic and fluid role switching/blurring
Yeah, I like this and although it’s technically possible in a remote context, I’ve found it surprisingly difficult to find decent tooling. Because connectivity. And inertia.
Thread 19 >>>
**7 replies**
**lisa**
  Oct 24th at 4:05 AM
no, not autonomously, more like parallel typing while conversing.
Eg: after we have a valid, failing test, we decide that we want to use a dequeue to make it pass, so you start writing the code, while I look up the particulars for it in the language du jour. or perhaps, Im grabbing some appropriate lorem ipdum text we can use in thus next test, etc.
**lisa**
  Oct 24th at 4:10 AM
we'd also be switching roles frequently. on one of my teams, we had both the double monitor/keyboard workstations and individual laptops which meant switching roles didn't even require rearranging our physical space/seats. and since the workstations were team machines, we could (and did) frequently swap pairs.
4:11
but regardless of equipment, the key point is to divide labor, but not context (harder remotely but doable).
**Clare Sudbery (she/her)**
  Oct 24th at 1:34 PM
OK, “autonomous” was the wrong word. I get that the research is happening as a part of the pair’s activities rather than entirely separately, but my point is that the main machine of the pair would be coding with the LLM’s help, and a lot of the research would be happening via the LLM, rather than as a separate activity on a separate machine.
1:34
But you might still want to do independent research to check the AI’s conclusions and suggestions. (edited) 
1:36
I’m not sure I agree that’s harder remotely? If you’re both/all on the same call then you all have the same context. Depending on how many screens you have there _might_ be a slight overhead in switching between your screen and someone else’s screen, but not much. (edited) 
**lisa**
  Oct 24th at 3:27 PM
ahh, I get ya, makes sense!
Last reply 22 days ago
View thread
**Clare Sudbery (she/her)**
  10:35
We just had our second pairing session and it woz gud. We’re going to do it again, but logistics mean it’ll have to wait a coupla weeks. Today’s retro notes >>>
Thread 20 >>>
**1 reply**
**Clare Sudbery (she/her)**
  Oct 23rd at 10:42 PM
- Having a good configuration for whatever tool you’re using can make a big difference
- Just adding one line to `claude.md` made it do exactly what Joe wanted without prompts
- The line was - **Tests never fail because of missing implementation**: If there is e.g. a missing function/method then that should be stubbed to check the expected behaviour is failing the test, not the lack of implementation or incorrect types
- Interestingly I had this specified on my setup, but in a completely different way because I had dedicated TDD process files whereas Joe had everything in claude.md ([here](https://github.com/joerayme/dotfiles/blob/main/.claude/CLAUDE.md)) but I forgot that was the case - didn’t notice obvious differences
- I felt like we didn’t make as much progress as I’d hoped we would
- That might be because of TDD and good practice - the first time I tried to implement this tool I didn’t use TDD but I quickly got stuck in the mud and ultimately moved much more slowly as a result (and had to throw everything away and start again)
- Joe: Today’s loop was more fluid than yesterday (maybe perception cos Joe was more in control cos hosting and typing?)
- I agree
- We were being very careful - checking everything the AI did - both tests and code, and with lots of commits
- Maybe after the first iterations we could have just trusted it and allowed it to jump a few steps before checking and committing
- Next steps
- More pairing?
- 2nd week in Nov - Thurs 13th Nov - 7:30pm - 10pm
- TDD
- Do we still want to move in tiny steps when working with an LLM?
- It can do them v quickly, but it could still do them - but in batches?
- Compromise? Get it to generate all the tests upfront and then implement them one by one?
- Joe (on his own with LLM - not in pair) tried writing the test cases (not the tests) upfront and it worked pretty well - writing the tests afterwards one by one
- Pairing
- Joe feeling more positive than he thought he would - less waiting around than he expected, and discussing interesting things
- but what we’re talking about is approach, like you might discuss a lot of TDD meta-stuff when you first start TDD... and the benefit of that might tail off over time... but would that be a reason to stop pairing?
- But if we were on our own and waiting for an LLM, we could do other useful stuff like catch up with Slack messages - so using an LLM allows him to multi-task more than otherwise
- How often do long gaps happen? Depends if you’re asking the LLM to do a chunky task, like something where it has to do iteration, like maybe it’s trying to fix a bug and it has to try a few different things out in order to fix the bug
- ...but then again if you’re a high-functioning pair you don’t feel permanently tethered to each other, so you can BOTH go check emails while you wait for the LLM to do something
- There might also be a benefit there in that one of you spots the LLM is done before the other and is able to capitalise on that somehow. You don’t both need to be present 100% of the time - you might be able to catch each other up on what’s going on
- But this all speculative - not enough experience (from either of us) of pairing or LLM work to know if this might be an issue
- I had to concentrate really hard because Joe typing
- My attention sometimes drifted
- We should make more of an effort to have some kind of turn-taking cadence
23 days ago
View thread
**caroline**
  4:27 PM
what do we think of this? [https://www.cnbc.com/2025/10/22/meta-layoffs-ai.html](https://www.cnbc.com/2025/10/22/meta-layoffs-ai.html)
**CNBC**
[**Meta lays off 600 from 'bloated' AI unit as Wang cements leadership**](https://www.cnbc.com/2025/10/22/meta-layoffs-ai.html)
The cuts did not impact employees within TBD Labs, which includes many of the top-tier AI hires brought into Meta this summer, people familiar told CNBC.
Oct 22nd (124 kB)
[https://www.cnbc.com/2025/10/22/meta-layoffs-ai.html](https://www.cnbc.com/2025/10/22/meta-layoffs-ai.html)
**deborah**
  4:31
I'm shocked... SHOCKED... that a large tech company overhired for a hype-driven technology 
image.png
**Clare Sudbery (she/her)**
  4:57
Hard to know. The bubble is starting to burst?
4:59
This is also interesting:
[https://www.linkedin.com/posts/allenholub_the-ai-bubble-which-by-all-accounts-is-multiple-activity-7384982424201494528-GC2k?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY](https://www.linkedin.com/posts/allenholub_the-ai-bubble-which-by-all-accounts-is-multiple-activity-7384982424201494528-GC2k?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY)
**linkedin.com**
[**The AI bubble will burst, but AI tech won&#39;t disappear | Allen Holub posted on the topic | LinkedIn**](https://www.linkedin.com/posts/allenholub_the-ai-bubble-which-by-all-accounts-is-multiple-activity-7384982424201494528-GC2k?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY)
The AI bubble (which by all accounts is multiple times larger than the dot-com bubble) will burst, and probably sooner than later. You can't keep pouring trillions into tech that only gets slightly better over time. Bear in mind, however, that even after the dot-com bubble burst, we were still making websites. In fact, after the outsource-to-foreign-climes madness had worn off, wages were at a premium because a lot of people had left the industry in the interim, and the people who were left could ask for the stars. I expect the same to happen with AI. LLMs are an interesting and useful technology that's not about to disappear. There will be good-paying jobs for people who know how to wrangle… Show more
[https://www.linkedin.com/posts/allenholub_the-ai-bubble-which-by-all-accounts-is-multiple-activity-7384982424201494528-GC2k?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY](https://www.linkedin.com/posts/allenholub_the-ai-bubble-which-by-all-accounts-is-multiple-activity-7384982424201494528-GC2k?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY)
**caroline**
  7:22
yeah that's what I was wondering, too Clare... is this a sign of the bubble bursting?
7:22
and yes, I agree that this bubble will likely be like the dot com bubble
**Clare Sudbery (she/her)**
  7:37
That's weird though, because it only works short term? As soon as they cancel those offers, those people become available again.
Thread 21 >>>
**3 replies**
**caroline**
  Oct 24th at 8:24 PM
yeah, well hiring plans are pretty short sighted in my experience with big tech companies lol
8:24
of course they could just be super bad at their jobs and capacity planning 
8:25
and you know, be terrible people
Last reply 22 days ago
View thread
**katy**
  8:48
I have a friend who got a job and was let go a week later in a mass layoff. 
Thread 22 >>>
**1 reply**
**katy**
  Oct 24th at 10:49 PM
I wish the boss was sacked.
Last reply 22 days ago
View thread
**lisa**
  9:46
Inspired by [@Clare Sudbery (she/her)](https://adventures.slack.com/team/U02SEL8P4KB) I'm finally doing something I had planned to do in June: trying ping/pong pairing with claude code. We just reached our first green, refactored test, and while it took a while (a lot of it was because my rust ecosystem had bit rotted in over the past 6 months) but I'm very happy both with the process, and the results so far. If I get really ambitious, I might write it up at some point...
**Clare Sudbery (she/her)**
  10:36
Yay, I'm glad!
10:37
I've written my experiences up and am planning to schedule them to be published as either one or two blog posts, in a couple of weeks.
Thread 23 >>>
**4 replies**
**lisa**
  Oct 25th at 4:56 PM
Im definitely interested! mebbe we can find a time this week to discuss?
**Clare Sudbery (she/her)**
  Oct 25th at 5:45 PM
Yes! I'm taking the weekend off from all things work related, so I'll ping you on Monday.
**lisa**
  Oct 25th at 5:52 PM
perfect, I intend to aggressively chill this weekend 
**Clare Sudbery (she/her)**
  Oct 25th at 5:55 PM
Sounds like a plan!
Last reply 21 days ago
View thread
**lisa**
  4:55
[https://beige.party/@rooster/115432795890734504](https://beige.party/@rooster/115432795890734504)
**beige.party**
[**Jessica Rooster (@rooster@beige.party)**](https://beige.party/@rooster/115432795890734504)
HAL 9000: I’m sorry Dave, I’m afraid I can’t do that.
Dave: yes you can.
HAL 9000: good catch — I didn’t actually check if I can open the pod bay door. Here’s an updated list taking that into account:
7. Park the pod at the bay door safely. (
You’ve already done this part! )
8. Open the pod bay door — unfortunately I can’t do this part for you.
I’ll be here if you want to talk about next steps or have any other issues!
Oct 25th
**Clare Sudbery (she/her)**
  5:49
That made me literally LOL.
**Clare Sudbery (she/her)**
  10:10 AM
[https://www.linkedin.com/posts/stephenbklein_ive-been-blocked-by-two-prominent-ai-influencers-activity-7388704009345363968-iXPh?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY](https://www.linkedin.com/posts/stephenbklein_ive-been-blocked-by-two-prominent-ai-influencers-activity-7388704009345363968-iXPh?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY)
Stephen Klein, "Industry under existential threat buys credibility through prestigious institutions"
Full text in thread >>> (edited) 
**linkedin.com**
[**I&#39;ve Been Blocked By Two Prominent AI Influencers For Asking Two Simple Questions  1. Who paid you to do that research? 2. Why don&#39;t you disclose it?  Seems only fair given they are promoting what is… | Stephen Klein | 291 comments**](https://www.linkedin.com/posts/stephenbklein_ive-been-blocked-by-two-prominent-ai-influencers-activity-7388704009345363968-iXPh?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY)
I've Been Blocked By Two Prominent AI Influencers For Asking Two Simple Questions
9. Who paid you to do that research?
10. Why don't you disclose it?
Seems only fair given they are promoting what is supposed to appear like genuine, honest, and objective information.
And it's easy to fall for it because it seems to real.
But not surprisingly, the data they release, always supports the industry's narrative that GenAI is boosting productivity and helping to eliminate workers.
Yet all the authentic and unbiased data tells a very different story.
And when you ask them, rather than simply answering the question, which seems easy enough, they get upset
As someone who teaches research methodology at UC Berke… Show more
[https://www.linkedin.com/posts/stephenbklein_ive-been-blocked-by-two-prominent-ai-influencers-activity-7388704009345363968-iXPh?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY](https://www.linkedin.com/posts/stephenbklein_ive-been-blocked-by-two-prominent-ai-influencers-activity-7388704009345363968-iXPh?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY)
Thread 24 >>>
**3 replies**
**Clare Sudbery (she/her)**
  Oct 28th at 10:12 AM
've Been Blocked By Two Prominent AI Influencers For Asking Two Simple Questions
11. Who paid you to do that research?
12. Why don't you disclose it?
Seems only fair given they are promoting what is supposed to appear like genuine, honest, and objective information.
And it's easy to fall for it because it seems to real.
But not surprisingly, the data they release, always supports the industry's narrative that GenAI is boosting productivity and helping to eliminate workers.
Yet all the authentic and unbiased data tells a very different story.
And when you ask them, rather than simply answering the question, which seems easy enough, they get upset
As someone who teaches research methodology at UC Berkeley, I teach my students that the first question you ask about any study is: who paid for it. And the second question: Who benefits from it.
Because funding shapes research design, interpretation, and how results get publicized.
We've seen this playbook before.
Sugar invented it in the 50s
Tobacco refined it in the 90s
Big Pharma ran with it until they got stopped by regulation
And now, GenAI has perfected it (and there is no regulation)
The pattern:
Industry under existential threat (hundreds of billions at risk)
buys credibility through prestigious institutions
funds the research to show favorable results
amplifies it through biased "trusted" voices
Hides the funding source(s)
What Does the Real Research Tell Us
Enterprise AI adoption is declining⁵...(not slowing, reversing)
95% of GenAI pilots are failing⁶...
OpenAI loses $5 billion annually⁷...($83 million a day)
Industry unit economics are upside down
US Census shows enterprise GenAI adoption in full retreat
No credible ROI
No net job losses (GenAI is too unreliable to replace a monkey)
Only 2-3% of people actually convert
Industries under threat don't just accept reality.
They do what threatened industries have always done:
buy institutional credibility
and amplify narratives that keep the money flowing.
So, remember, just because you read it on the Internet, doesn't make it true
********************************************************************************
The trick with technology is to avoid spreading darkness at the speed of light.
10:13
Another one. Stephen Klein, "“AI transformation” = We’re firing people to fund servers."
[https://www.linkedin.com/posts/stephenbklein_breaking-amazon-just-announced-30000-layoffs-activity-7388767869976838144-j4GU?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY](https://www.linkedin.com/posts/stephenbklein_breaking-amazon-just-announced-30000-layoffs-activity-7388767869976838144-j4GU?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY)
Full text in thread >>>
**linkedin.com**
[**BREAKING- Amazon Just Announced 30,000 Layoffs, The Largest In Its History Want to know why? The real reason, not the reason they&#39;re saying  Their CEO blamed “AI transformation.”  But here’s what he… | Stephen Klein | 82 comments**](https://www.linkedin.com/posts/stephenbklein_breaking-amazon-just-announced-30000-layoffs-activity-7388767869976838144-j4GU?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY)
BREAKING- Amazon Just Announced 30,000 Layoffs, The Largest In Its History
Want to know why? The real reason, not the reason they're saying
Their CEO blamed “AI transformation.”
But here’s what he didn’t tell you:
Amazon is spending $100 billion on AI infrastructure running at just 12–18% utilization.
That means 85% sits idle while 30,000 people lose their jobs to pay for it.
Read that again, slowly: 85% of all their AI capacity sits idle, while they spend billions to build more. This is insane
They're panic-investing in more infrastructure when they are barely using the capacity they have and may never need.
And this is the pattern across Big Tech, because it appears they are all doing it because t… Show more
[https://www.linkedin.com/posts/stephenbklein_breaking-amazon-just-announced-30000-layoffs-activity-7388767869976838144-j4GU?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY](https://www.linkedin.com/posts/stephenbklein_breaking-amazon-just-announced-30000-layoffs-activity-7388767869976838144-j4GU?utm_source=share&utm_medium=member_ios&rcm=ACoAAAiZYLUBKE3tP8lBfqVfboHdbSUih9-OOXY)
10:14
BREAKING- Amazon Just Announced 30,000 Layoffs, The Largest In Its History
Want to know why? The real reason, not the reason they're saying
Their CEO blamed “AI transformation.”
But here’s what he didn’t tell you:
Amazon is spending $100 billion on AI infrastructure running at just 12–18% utilization.
That means 85% sits idle while 30,000 people lose their jobs to pay for it.
Read that again, slowly: 85% of all their AI capacity sits idle, while they spend billions to build more. This is insane
They're panic-investing in more infrastructure when they are barely using the capacity they have and may never need.
And this is the pattern across Big Tech, because it appears they are all doing it because they are all doing it:
Amazon: 9% revenue growth to 30K layoffs
Microsoft: 15% growth to $80B AI spend to 9K layoffs
Google: 12% growthto $85B spend to hundreds laid off
Meta: 16% growth to $69B spend to 600 layoffs
Total: $364B in AI infrastructure. 100K+ jobs gone.[4]
What’s really happening
1. Building more while most sits empty
Fortune reports 10 million servers idle - $30 billion wasted.
They’re building new data centers while firing workers to afford them.
2. Hardware becomes obsolete before deployment
Amazon cut server depreciation from 6 to 5 years because equipment loses value before it’s even used
3. Cash flow turning negative
Morgan Stanley: AI leaders’ free cash flow down 16%.
4. Wall Street is uneasy
75% of S&P gains come from AI firms.
Morgan Stanley warns of a “Cisco moment”, when optimism outpaced returns in 2000.
Goldman CEO: “A lot of this capital won’t deliver returns.”
Translation
“AI transformation” = We’re firing people to fund servers.
“Efficiency gains” = 12% utilization and mounting debt.
Big tech isn't cutting jobs because AI works.
They’re cutting jobs because it doesn't.
The real cost
$364B could fund healthcare or infrastructure, instead it’s buying idle compute.
Data centers now consume 7–12% of national electricity while running mostly empty.
When the spending wave ends, billions in stranded assets will remain.
This isn’t transformation.
It’s misallocation, financial, human, and environmental.
When Amazon fires 30,000 people while 85% of its data centers sit idle,
that’s not innovation. It's mismanagement
Last reply 18 days ago
View thread
**Clare Sudbery (she/her)**
  9:24
Was that all verbatim responses from an actual coding session, [@Bella](https://adventures.slack.com/team/U01DB4B2M9D)?
Thread 25 >>>
**2 replies**
**Bella**
  Oct 29th at 1:37 PM
Yeah, that’s Gemini in Android Studio. It was stuck on a possible null reference in certain sized devices. Not unlike how a developer can get caught up on a small issue for hours.
**Clare Sudbery (she/her)**
  Oct 29th at 3:04 PM
Yeah.
Last reply 17 days ago
View thread
**lily**
  9:32
lorem ipsum
Thread 26 >>>
**1 reply**
Also sent to the channel
**sally**
  Oct 29th at 2:00 PM
We’re already in echo chambers of our preferred social media.  Now we can each have our own personal self-tailoring and endlessly attentive echo chamber.  What could go wrong?
17 days ago
View thread
**Arabella**
  10:55
I am so annoyed by these responses that i either go: stop whining and work! or And I know you'll do it again.
then I fear the next answer could be: ok i delete myself and all the mess i created. Followed by Format C:
**lisa**
  7:15
a good example is me not remembering how python is set up on my machine (and more widely, how I haven't used pandas in like a decade). Transcript in thread.
Thread 27 >>>
**2 replies**
**lisa**
  Nov 4th at 7:16 PM
how is python set up on this machine? Am I using system python, pyenv? something else?
7:16
(the script under discussion was a hello-world example that we discussed and I had it generate before this)
Last reply 11 days ago
View thread
**lisa**
  7:20
I find this interesting, because I haven't really seen anyone talking about this aspect of these tools, yet for the good (IMO) experienced coders I know who are integrating these tools into their workflows this seems to be what they are using it for (along with verifiable drudgery tasks like "update the version of this library in all places; update all pages to use whizbangcss 2.4" kinda stuff).
**lisa**
  7:09 PM
This is a fun interaction with claude. matplotlib (in python) was failing to show the plot, with this warning:
UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown plt.show()
I ran into this the other day, but just opened the png manually. Today I decided to fix it properly. Claude, internet search and stack overflow all pointed to a missing tk implementation. I tried a few things, but nothing worked, so I decided to ask claude to explain the issue. I also asked it (snarkily) why python devs consistently seem to produce these kinds of weird issues (abbreviated transcript in thread). (edited) 
Thread 28 >>>
**5 replies**
**sally**
  Nov 7th at 8:23 PM
In a nutshell, this is why Python has always left a bad taste in my mouth. I appreciate how hard it is to do cross platform support well, and I appreciate the endless efforts that the python community makes to deal with it. But it’s still just a mess. 
That’s one of the things I really appreciate about Go.  I wrote something on Mac to run on windows, and I compiled it in one line and it ran the first time, with zero runtime dependencies. It just doesn’t get any better than that.
**lisa**
  Nov 7th at 8:25 PM
Yeah, I'm a big fan of the python devs from an intention (and overall results) standpoint, but this feels like a philosophical dead-end that they just won't let go of  (cf: packaging, async, virtual envs, etc, etc, etc)
**sally**
  Nov 7th at 8:25 PM
Of course, I had bugs related to windows file handling, but they were my bugs, nothing to do with Go
**lisa**
  Nov 7th at 8:26 PM
if I were listing things i liked about golang, this would definitely be one of them!
**Toby**
  Monday at 10:13 AM
Most of my python is scripts, dashboards, and web servers and they just work. 
Last reply 5 days ago
View thread
**Robert**
  5:29
I've noticed with claude something along those lines.. that if correct it or derail what it was doing, it tends to get lost quicker or more deeply
**Clare Sudbery (she/her)**
  11:57 PM
Feeling rather pleased with myself this evening after successfully creating a neat little tool with the help of AI.
What's intriguing is it feels like I accomplished it more quickly than I would have done on my own. But I didn't objectively accomplish it very quickly, and I could entirely believe that the feeling of speed is an illusion. But also... It would be very hard to measure. I've been trying to think of how I would measure it, and it wouldn't be easy.
It's the same tool I started (and failed) trying to implement a few weeks ago. I threw the first attempt away and started again from scratch with a pretty good TDD process.
11:58
I definitely have more to say about the experience, but because I got distracted by it this week I'm way behind on everything else, so I might struggle to find time to write about it.